+++
title = "AgentTuning: Enabling Generalized Agent Abilities for LLMs"
author = ["keimoriyama"]
description = "description"
date = 2026-01-12T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://aclanthology.org/2024.findings-acl.181/)
-   ACL 2024 findings


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   NLPとエージェントタスクの損失関数の重み付き和を使うことで、NLPタスクの性能を維持しつつ、エージェントタスクの性能が向上する。


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   LLMのエージェント性能を向上させるためのデータセット構築、学習パイプラインを提案した


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   既存のエージェントタスクの手法はプロンプトや特定のエージェントタスク偏っている
-   NLPにおけるタスクの能力を維持しつつ、エージェントタスクの能力を向上する必要がある


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   データセットの構築には、self-instrcutを使用している
    -   既存のデータセットにあるユーザーとエージェントのインタラクションの続きを、GPT-4により生成する
    -   最終的なエージェントの行動の結果は報酬として評価される
        -   この報酬は、タスク毎に設計されていて、報酬の値を基にフィルタリングをしている
-   学習に使用するデータセットは、上記の方法で構築されたデータセットと指示学習用のものの二つを用いる
    -   損失関数には、それぞれのデータセットに対するクロスエントロピーの重み付け和を使用している


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   held-in、heol-outなタスクにおいてGPT-4や3.5と同等の性能を示した
    -   これが公平な比較になっているかは分からない
-   公開されているLlamaよりも基本的なエラーが減少している
-   学習には、エージェントタスクだけではなく、指示学習用のデータも混ぜた方が汎化性能が向上する
    -   出力を見た感じでは、想定しているエージェントタスクと違うのかも？


## ❓疑問点は何か {#疑問点は何か}

-   損失関数を混ぜることと、継続学習でどちらが有効なのか気になった
