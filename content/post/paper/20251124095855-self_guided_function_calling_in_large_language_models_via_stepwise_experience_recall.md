+++
title = "Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall"
author = ["keimoriyama"]
description = "description"
date = 2025-11-24T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall](https://aclanthology.org/2025.findings-emnlp.574/)
-   EMNLP 2025 findings


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   LLMのFunction Callingタスクのデータの拡張のためには、呼び出されているタスクの一致度なども入れると良い


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   LLMを外部APIと連携するタスクであるFunction Callingの性能を向上するような学習する
-   学習に使用するプロンプトに含める例を工夫する手法にしている


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   学習データやモデルのパラメータ数を単に増やしても、実世界インタラクションは解決することができない
-   既存のFunction Callingの学習手法は、具体例を手動で付与しているため大規模にしづらい課題がある


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   類似の例を取得するための方法として、以下の三種類の指標を用いる
    1.  ユーザーのクエリと軌跡の埋め込み表現の類似度
        -   軌跡とは、ユーザーの入力と呼び出されたツールの応答を複数ステップ繰り返したものを指す
        -   類似度の指標には、正規化コサイン類似度を使用する
    2.  呼び出しツールの一致度
        -   実際に使用されているツールの一致度を使用している
    3.  意図アラインメント
        -   使用する意図は、事前に定義されているクラスに分類されている
        -   類似度の検索に使用する履歴が与えられた時に意図を何らかの方法で推定しているのかも？
-   最終的な類似度は、これらの重み付け和になっている
-   類似度を計測するためのデータ集合は新たな軌跡が得られた時に更新する
    -   LLMでユーザーの意図が達成できたと分類された時にデータ集合に追加する


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   ToolQAや&tau;-benchによる評価では、既存手法よりも概ね良い性能であった
    -   ベースライン手法はTool Augmented LLMらしい
-   Ablation Studyでは、2と3の指標のどちらも重要っぽいことが示されている
    -   ToolQAのEasyでは3を無くすとスコアが大きく下がり、Hardでは2を無くす時が大きくスコアが下がった
    -   全体的には3の影響度が大きそうだけど、これは良く分かんないなあ


## ❓疑問点は何か {#疑問点は何か}

特になし
