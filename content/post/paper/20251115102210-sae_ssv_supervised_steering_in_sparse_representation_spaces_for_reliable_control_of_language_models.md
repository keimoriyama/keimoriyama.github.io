+++
title = "SAE-SSV:Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models"
author = ["keimoriyama"]
description = "description"
date = 2025-11-15T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models](https://aclanthology.org/2025.emnlp-main.112/)
-   EMNLP 2025 main


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   SAEを用いた特徴量を用いて介入を行うことで、LLMをより良く制御することができる


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   自由記述タスクにおけるLLMへのパラメータ介入手法の性能を向上すること
-   特に、介入に使用する適切なベクトルを構築することを目的する


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   LLMの生成文章を制御する方法として、中間表現を制御するステアリングがある
-   既存のステアリング手法の評価は、QAや選択問題などの制約がある
-   加えて、ヒューリスティックな方法であるため文脈などを取りこぼすことがある


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   Sparse Auto Encoder(SAE)を使用して、介入する方向を決めること
    -   エンコーダの出力が、入力次元数よりも大きいAuto Encoderのこと
-   SAEが抽出したベクトル表現を使用して、Probingを行いそのタスクにおいて有効な特徴量を見つけている
    -   特徴量を見つけるために、F-Statisticを使用して次元削減をしているっぽい
    -   これ以外にも、学習した線形モデル（Probe）の次元削減をするための工夫がある
-   複数のProbeを学習し、その平均ベクトルを介入ベクトルとする
-   この介入ベクトルを最適化するために、追加の学習をすることで微調整する
    -   ポジティブとネガティブに分類されたデータからSAEが抽出した特徴量に介入する
    -   この介入後の特徴量が、ポジティブなデータとネガティブなデータの特徴量のセントロイドに近くなるように学習する
    -   加えて、言語モデル自体の損失関数や介入ベクトルに対するL1損失を制約として使用している


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   性能的には、既存の介入手法よりも良いスコアになっている
-   SAEにより抽出された特徴量が良くクラスを分類できる特徴量になっていることが分かった
    -   SAEによる特徴量の抽出を用いた介入の有効性を示している
-   Ablation Studyにより損失関数の必要性が示されている
    -   Probeの学習を行わないと、出力文章の整合性や論理性が無くなる

    -   言語モデルの損失を無くすと、ベースになる言語モデルの応答を保持することが難しくなる

-   介入の方向については提案手法で良い方向を見つけることができたが、大きさについては未知である


## ❓疑問点は何か {#疑問点は何か}

-   手法が複雑だと思った
-   SAEの学習やProbingの調整に必要な計算コストがどれくらいなのが気になる
-   評価にLLMを使用するのが適切であるかどうか分からない
    -   生成された文章が対象の文章を適切に反映できているのかを評価させている
-   ベースモデルの評価が無いのが気になる
    -   Ablation Studyに一応あった
