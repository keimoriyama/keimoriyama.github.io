+++
title = "APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets"
author = ["keimoriyama"]
description = "APIGen Automated Pipeline for Generating Verifiable and Dieverse Function-Calling Datasets"
date = 2025-11-10T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   （1, 2文でまとめる）


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   Function Callingとは、自然言語の指示にの応答を生成するために必要なAPIを叩き、必要な情報を得るタスクのことを指す
-   この論文では、このタスクの学習に必要なデータを自動生成するためのパイプラインを提案している


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   既存のfunction callingデータセットは実用のためには不十分である
    -   例えば、学習データ内で使用されているAPIが一部のカテゴリに偏っている場合、そのデータで学習されたLLMエージェントは他のAPIからのデータの取得ができなくなるという課題がある。
-   そのため、多様なAPIを扱うデータセットが必要になる


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   提案手法は、データの生成と多段階によるフィルタリングから構成されている
-   データの生成
    1.  既存のAPIを用いたQAペアをJSON形式に変する。
    2.  プロンプトはデータ生成の目的になるテンプレートを選択し、QAペアを生成させる
    3.  生成されたペアをJSON形式に変換する
-   生成されたデータをフィルタするために以下の3つの方法を用いる
    1.  フォーマットの検証：生成されたJSONのフォーマットが正しいか、APIの呼び出し時に適切な引数を指定しているか検証する
    2.  実行可能性の検証：データに含まれたAPIが実行可能であるか検証する、実行可能ではない場合、フィルターする
    3.  文法の検証：複数のLLMを用いて、目的を達成するための関数を呼び出すことができるかなどを総合的に評価する
-   データの多様性を確保するために、テンプレートを複数用意することや、基データからどのようなデータをサンプリングするかを工夫している


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   ToolBenchを基データとして生成を行った
    -   基データとして活用するために、いくつかのフィルターを適用したの3500件を使用している
-   生成パイプラインを様々なLLMを用いて検証した所、小規模なモデルは無効なAPIを呼び出る例が多い

-   学習したモデルの評価はBerkley Function-Callingデータセットを使用している
-   FCのために学習されたLLMはGPT-4oなどよりも良い性能を示している
    -   学習に使用しているLLMは1Bと7Bのモデルなので、より小規模なパラメータになっているかも？
-   各フィルタリングステップにおいて、フィルター後のデータを用いてモデルを学習し、評価した
    -   上の説明において、フォーマットの検証のみを適用したデータ、1と2を適用したデータ、全てを適用したデータに分けている
    -   評価結果としては、全てを適用したデータにより学習されたLLMの性能が最も良かった
    -   このことから、提案したフィルター方法の有効性が分かる


## ❓疑問点は何か {#疑問点は何か}

-   GPTとかのモデルの比較って平等な比較になっているのか疑問だった
-   生成されたデータの多様性の評価は行われていないのが気になった
    -   プロンプトのテンプレやデータの持ってき方の工夫で十分なのかな
