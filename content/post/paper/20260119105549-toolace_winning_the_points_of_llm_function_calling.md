+++
title = "ToolACE: Winning the Points of LLM Function Calling"
author = ["keimoriyama"]
description = "description"
date = 2026-01-19T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [ToolACE: Winning the Points of LLM Function Calling](https://openreview.net/forum?id=8EB8k6DdCU)
-   ICLR 2025


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   人工APIをLLMが生成することで、LLMのツール呼び出しの性能を向上させることができる。


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   ツール呼び出しタスクの学習に使用するためのデータを生成するパイプラインを作成する
-   マルチターンなどの複雑なタスクが必要な状況を想定する


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   現実世界におけるツール呼び出しは複雑である
    -   ユーザーの指示の多様さや曖昧さ、zero-shot推論だけではなく、複数のツールの組み合わせが必要なケースがある


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   データ生成パイプラインとして以下の3ステップを提案した
    1.  ツール生成
        -   Tool Self-Evolution Synthesisという方法を提案した
        -   最初に、事前学習用のデータからAPIの情報を抽出する
            -   人工APIの分類を指しているのかも？
        -   作成したノードを基に、APIが対応している範囲を調査する
            -   フィードバックをしていると考えて良さそう
        -   フィードバックを基に、APIの仕様を改善する

    2.  対話生成
        -   user、assistant、toolのそれぞれのroleをLLMが生成する
        -   対話の複雑さを評価するために、コンテキストから次のステップのトークンが生成される確率の平均値を使用している
    3.  検証
        -   ルールベースの評価とLLMによる評価によるデータセットの評価が適用される

        -   LLMの評価は、ハルシネーションの確認、レスポンスの一貫性、ツール呼び出しの適切さで評価される


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   8Bモデルを学習し、BFCLとAPI-Bankで評価した
-   BFCLの評価では、オープンソースのモデルよりも良い性能であった
    -   xLAMよりも性能が良く、GPT-4oの一部のモデルよりも良い
    -   特に、Non-liveが強くなっている
-   API-Bankにおいても同様の傾向がある


## ❓疑問点は何か {#疑問点は何か}
