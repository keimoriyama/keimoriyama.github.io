+++
title = "Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention"
author = ["keimoriyama"]
description = "description"
date = 2025-12-24T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention](https://aclanthology.org/2025.acl-long.634/)
-   ACL 2025
-


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   （1, 2文でまとめる）


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   Vison-Languageモデル(VLM)の内部表現に介入することで、ハルシネーションを防ぐこと
    -   ここでのハルシネーションは、画像に写っていない物体についてモデルが言及する現象を指す


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   VLMのハルシネーションを防ぐことは、実用上重要
-   既存の手法はデータの品質や損失関数の工夫などでこれに対処してきた
    -   学習に必要な計算コストが大きいため、実地に適応するために時間がかかる
-   他の学習無しの手法では画像の優先度を上げるようにしているが、画像内のAttentionなどの特定の仮定に依存している


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   MSCOCOを使用して、VLMの中間表現をProbingする。
    -   ハルシネーションをしているかどうかは、トークンがMSCOCOのクラスの単語がそれの類義語を含むかどうかで判定している
-   介入するベクトルは、ハルシネーションが無いトークンの中間表現の平均ベクトルからハルシネーションしているトークンの中間表現の平均ベクトルを引いたベクトルを用いる
-   文章の生成時には、正の方向と負の方向に介入した二つのモデルが生成するロジットを足したものを使用している
    -   介入する量は個別に設定している


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   ベンチマークにおける評価では、正解率とF1スコアが改善している
    -   使用するデータはハルシネーションのベンチマーク
    -   既存のハルシネーション対策をする手法よりも良くなっている
    -   既存の画像理解ベンチマークにおいても他の手法と同等の性能になっている
-   介入量毎の性能を見ると、正の方向への介入量はパフォーマンスに大きく影響する


## ❓疑問点は何か {#疑問点は何か}

-   ハイパラの量が増えているのは良いのか？
-   著者らも言及しているが、カテゴリ名などはMSCOCOに依存している
    -   これ難しい問題だと思った
