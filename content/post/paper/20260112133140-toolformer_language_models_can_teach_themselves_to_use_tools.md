+++
title = "Toolformer: Language Models Can Teach Themselves to Use Tools"
author = ["keimoriyama"]
description = "description"
date = 2026-01-12T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [Toolformer: Language Models Can Teach Themselves to Use Tools](https://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html)
-   NeurIPS 2023


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   データ拡張にAPIを用いることで、下流タスクにおける性能が向上する。


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   自己教師有り学習により、外部ツールをLLMが使用する方法を学習する
    -   評価と違う点があるから、読み違えているかも
-   テキストデータから、Tool Callingデータセットを作成する


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   既存の手法は、大規模な人手アノテーションが必要であることや、特定のタスクのみを対象としている
-   そのため、学習したLLMの応用先が限られるという課題がある


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   データ拡張にはテキストデータを用いる
    -   疑似APIをLLMを用いて生成する
        -   疑似APIの形式は `QA(c)-> r` のような感じ
        -   使用するタスクとしては、QAや計算問題を用いている
    -   生成された疑似APIを実行する
        -   実行は、LLMやPythonなどの環境ですることを想定している
    -   フィルタリングには、重み付きクロスエントロピーを基準として用いている
        -   生成されたトークンの損失と、何も生成されなかった時の損失の差が閾値よりも大きい時、データセットに含むようにしている
-   推論時には、 `->` トークンが生成されるまでデコーディングを行う
    -   ここでAPIの呼び出しが入るため、APIの結果を挿入して、デコーディングを再開する


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   QAや数学タスクにおける性能が向上した
    -   下流タスクにおける性能が向上している
-   Tool Callの評価が無いのが気になる
    -   目的がTool Callingの性能向上ではなく、Tool Callingを通した性能向上になるのかも


## ❓疑問点は何か {#疑問点は何か}

-   評価のやり方が適切であるかどうか分からない
    -   API callを実際にしているのか？
    -   下流タスクにおいて外部ツールを呼び出せるなら性能の向上は必然では？とも思う。
-   このデータ拡張のやり方は面白いと思った。
