+++
title = "Gorilla: Large Language Model Connected with Massive APIs"
author = ["keimoriyama"]
description = "description"
date = 2025-11-17T00:00:00+09:00
tags = ["paper"]
categories = ["paper"]
draft = false
+++

## 📄論文情報 {#論文情報}

-   [Gorilla: Large Language Model Connected with Massive APIs](https://www.proceedings.com/079017-4020.html)
-   NeurIPS 2024


## 🔑この論文のキーメッセージ {#この論文のキーメッセージ}

-   LLMのAPIを呼び出す能力は、LLM自身に与えられたAPIのドキュメントが正確であるか判断させながら学習を進めると良い
-   API呼び出しの評価はASTの部分木マッチングを使用すると良い


## 🎓どういう問題に取り組んだのか {#どういう問題に取り組んだのか}

-   LLMが外部のAPIを上手く活用するための学習方法を提案した
-   また、LLMのAPI活用能力を評価するためにベンチマークデータセットを構築した


## 🧑‍🎓その問題に取り組むことがなぜ重要なのか {#その問題に取り組むことがなぜ重要なのか}

-   APIを呼び出すためのコードをLLMが生成することはまだ難しいタスクである
-   APIの使用は頻繁に更新されることが原因の一つとして挙げられている


## 💡問題解決に向けたキーアイデアは何か {#問題解決に向けたキーアイデアは何か}

-   評価のために、APIBenchと呼ばれるベンチマークデータセットを構築した
    -   TorchHubなどにアップロードされているモデルカードから仮想APIの呼び出しコードを作成している
    -   このAPIについて指示をGPT-4を使用して生成している
-   Retriever-Aware Training
    -   プロンプトに含まれているAPIのドキュメントが不正確である可能性がある
    -   最初に、プロンプトに含まれているドキュメントが正確であるかを予測する
        -   学習データには、不正確なドキュメントを含めるように拡張している
    -   正確ではない予測した場合、そのドキュンメントを使用して推論しないように学習を促す
-   評価にはASTの部分木マッチングを使用している
    -   APIの引数には、必要ではないものが存在している
    -   そこで、構文木を作っておき、LLMの生成した呼び出しのコードが部分木であるかどうかを判定して評価している


## 👀新たに分かったことは何か {#新たに分かったことは何か}

-   学習したモデル（論文中ではGorilla）がベースラインモデル（GPT-4やLLama）よりzero-shotやFew-shotで良い性能であった
    -   Few-shotに使用するRetrieverを変えても同様の結果になった
-   ASTによる評価は、人手評価と同様の性能を示している


## ❓疑問点は何か {#疑問点は何か}

-   実装のイメージがつかない
    -   LLMが与えられたドキュメントを判断した後に、プロンプトの文言を追加するという事なのか
-   Gorillaはオリジナルのモデルではないよな？
    -   Llamaベースのモデルになると思うが、シンプルなSFTをした時との比較は無いのだろうか
