<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>K&#39;s blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on K&#39;s blog</description>
    <generator>Hugo</generator>
    <language>jp-JP</language>
    <lastBuildDate>Thu, 12 Feb 2026 21:35:52 +0900</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>まぐさ桶の犬</title>
      <link>http://localhost:1313/post/book/20260212210228-%E3%81%BE%E3%81%90%E3%81%95%E6%A1%B6%E3%81%AE%E7%8A%AC/</link>
      <pubDate>Thu, 12 Feb 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260212210228-%E3%81%BE%E3%81%90%E3%81%95%E6%A1%B6%E3%81%AE%E7%8A%AC/</guid>
      <description>&lt;p&gt;まぐさ桶の犬を読んだ。&#xA;この本を読もうとしたきっかけは、このミスで5位にランクインしていたことだ。&#xA;本を読む前は知らなかったが、シリーズ物の最新作らしい。&lt;/p&gt;&#xA;&lt;p&gt;本屋件探偵の葉村晶が、近所の人の付き沿いを依頼される。&#xA;その人の親族である富豪から人探しを依頼される。&#xA;しかし、探す人の周囲の人間が、失踪していたり、不審な死を遂げていたりする所に気づく所から話が始まる。&#xA;本当に冒頭の文章では、主人公の葉村が死にかける所から始まる。&lt;/p&gt;&#xA;&lt;p&gt;謎が謎を呼ぶ展開で、読んでいて飽きなかった。&#xA;次々と表れる癖の強い人間達の裏事情が後半で暴露されたり、暴かれたりしていた。&#xA;人の名前や関係性を把握するのが大変だったけど、何となくの理解でガンガン読み進めた。&lt;/p&gt;&#xA;&lt;p&gt;それでも楽しめたのは、この本が持つ独特の雰囲気なのかもしれない。&#xA;主人公の葉村の皮肉っぽい視点や痛む体の描写が、何となく読みやすさに繋っているのかもしれない。&#xA;謎解きの間に、この描写があるから読めたのかも。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ヨルガオ殺人事件</title>
      <link>http://localhost:1313/post/book/20260207211241-%E3%83%A8%E3%83%AB%E3%82%AC%E3%82%AA%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Sat, 07 Feb 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260207211241-%E3%83%A8%E3%83%AB%E3%82%AC%E3%82%AA%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6/</guid>
      <description>&lt;p&gt;ヨルガオ殺人事件を読んだ。&#xA;カササギ殺人事件の続きの話で、二つのミステリーを一つの小説で同時に楽しむことができた。&#xA;カササギ殺人事件と同じように、コンウェイの書いた小説であるヨルガオ殺人事件が小説内の世界で起きた事件に関連している。&#xA;その事件の真相に気づいた人が失踪する事件が起きてしまい、ヨルガオ殺人事件の編集者である主人公に失踪事件や殺人事件の真相を解く依頼が来る。&lt;/p&gt;&#xA;&lt;p&gt;ヨルガオ殺人事件のストーリーも、本編のストーリーも一つのミステリー小説として完成されきっていた。&#xA;しかも、これらの物語を関連付けて謎解きとして成立させる手腕は凄いなと思った。&#xA;事件の謎以外にも、主人公の妹との不穏な雰囲気にも謎があったりして、もやもやしている雰囲気を出しつつ、綺麗に解いていた。&#xA;主人公何者なんだよ。本当にただの基編集者なのか？&lt;/p&gt;&#xA;&lt;p&gt;ただ、人の名前を把握するのは一苦労だった。&#xA;小説二つ分だからしょうがないけど、これには苦労した。&#xA;巻頭に人物紹介が無かったら途中で読むのを止めていただろうなあ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment</title>
      <link>http://localhost:1313/post/paper/20260205100956-from_outcomes_to_processes_guiding_prm_learning_from_orm_for_inference_time_alignment/</link>
      <pubDate>Thu, 05 Feb 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260205100956-from_outcomes_to_processes_guiding_prm_learning_from_orm_for_inference_time_alignment/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.acl-long.946/&#34;&gt;From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL 2025 Long&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;（1, 2文でまとめる）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reward Guided Searchは、LLMが生成した複数の文章から報酬モデルの値を用いて文章を選択する手法である&lt;/li&gt;&#xA;&lt;li&gt;この文章の選択に使用する報酬モデルの出力に一貫性を持たせることを目指す&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;報酬モデルは、文章の全体を評価するように学習される&lt;/li&gt;&#xA;&lt;li&gt;そのため、文章の一部を評価する時に報酬の一貫性が無くなる課題がある&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特に、冗長な文章を高く評価する傾向がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;この報酬モデルを再学習するには計算コストが多くかかるため、既存のモデルを使用しつつ、報酬の計算を工夫することで、より良い文章の選択が可能になる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;スコアの計算時にscore consistencyの分析をしている&lt;/li&gt;&#xA;&lt;li&gt;Score Consistencyの定義&#xA;&lt;ul&gt;&#xA;&lt;li&gt;文章AとBにおける報酬値r(A)とr(B)がある時、AとBの部分文字列aとbにおける報酬r(a)とr(b)は、以下の関係が成立する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;r(A)&amp;gt;r(B) -&amp;gt; r(a) &amp;gt; r(b)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;RGSでは、新しいトークンを選択する時に、これまで生成された文章と新しいトークンを繋げた文章の報酬が最大になるように選択するため、重要な性質になる&lt;/li&gt;&#xA;&lt;li&gt;この時、部分文字列を評価することになるため、文章の部分文字列の評価の一貫性が必要&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;既存の報酬モデルは部分文字列の評価に一貫性が無いため、部分文字列を評価するためのデータセットを構築し、報酬モデルを学習した&lt;/li&gt;&#xA;&lt;li&gt;学習には、報酬モデルの分布の差のエントロピーを重みとして使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;文章全体を評価するように学習された報酬モデルは、Score Consistencyを満たさない&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;報酬モデルの学習に使用するデータセットの部分文字列が、良いと評価された文章の方が高くなる割合で評価した&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;5トークンで、57%くらいであり、50トークンまで増やすと60%まで上がる&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;一方で、人間との評価の一致度は高い&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;提案手法により学習した報酬モデルは、5トークンで55%、50トークンで65%まで改善した&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ベンチマークにおける評価は、報酬の平均値や文章の多様性などで評価&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;様々なチャンクで文章を区切る方法に提案手法により学習した報酬モデルを使用したっぽい&lt;/li&gt;&#xA;&lt;li&gt;報酬の値などのスコアを見ると、既存の手法を改善できていると言える&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;着眼点が良いと思った&lt;/li&gt;&#xA;&lt;li&gt;報酬モデルの学習が必要になっているのはネックになっていないのか気になった。&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>一九八四&#43;四〇 ウイグル潜行</title>
      <link>http://localhost:1313/post/book/20260130142055-%E4%B8%80%E4%B9%9D%E5%85%AB%E5%9B%9B_%E5%9B%9B_%E3%82%A6%E3%82%A4%E3%82%B0%E3%83%AB%E6%BD%9C%E8%A1%8C/</link>
      <pubDate>Fri, 30 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260130142055-%E4%B8%80%E4%B9%9D%E5%85%AB%E5%9B%9B_%E5%9B%9B_%E3%82%A6%E3%82%A4%E3%82%B0%E3%83%AB%E6%BD%9C%E8%A1%8C/</guid>
      <description>&lt;p&gt;「一九八四+四〇 ウイグル潜行」を読んだ。&#xA;中国のウイグル自治区からカザフスタン、日本に住むウイグルの人々を取材したルポだった。&#xA;最初に、ウイグル自治区を取材し、カザフスタンに出国、その後日本に帰国しウイグル人を取材していた。&#xA;取材の様子も十分な内容だったと思うけど、ウイグル自治区からカザフスタンに出国する際、中国当局に拘束された話が衝撃的だった。&#xA;長時間に及ぶ取り調べのなか、素性を調べ上げられた結果、しばらくの間中国への入国が禁じられていた。&#xA;現実にこういう話があるのは衝撃的だったし、どれくらい大変なのか全然想像できない。&lt;/p&gt;&#xA;&lt;p&gt;ウイグルとカザフスタンで、自由度が大きく違うなと感じた。&#xA;ウイグルの人に、宗教や収容施設の話を質問すると、「わからない」などの返答が多く返ってきた。&#xA;自治区内にも警察や監視カメラが多くあることに加え、撮影した写真を削除するように繰り返し注意されているのも目立った。&#xA;それに比べ、カザフスタンでは、取材相手が赤裸々に体験を語っていて、当局の監視もそこまで厳しくない様子だった。&#xA;自由度の違い以外にも、ウイグル自治区に住むカザフ人も収容所に入れられていたというのはびっくりだった。&lt;/p&gt;&#xA;&lt;p&gt;収容所はあるという事は事実っぽいが、これが悪であるかという議論についてはちょっとよく分からなくなってしまった。&#xA;人権侵害という面を切り取ってしまえば、そうなってしまうのだが、治安維持という面では必要っぽいように思える。&#xA;改めて視点が変わると、何もかもが変わるということは忘れないようにしたい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>カササギ殺人事件</title>
      <link>http://localhost:1313/post/book/20260121194325-%E3%82%AB%E3%82%B5%E3%82%B5%E3%82%AE%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Wed, 21 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260121194325-%E3%82%AB%E3%82%B5%E3%82%B5%E3%82%AE%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6/</guid>
      <description>&lt;p&gt;カササギ殺人事件を読んだ。&#xA;とても満足。&#xA;上下巻のから構成されていて、それぞれの巻において絡み合う別の殺人事件が展開されていた。&lt;/p&gt;&#xA;&lt;p&gt;特に冒頭は「？？？」となるような書き出しで、読む本間違えたか？と思った。&#xA;読了した今、この冒頭は計算されていて、著者が意図した通りに感情を操られたような気分になる。&#xA;それぞれのミステリーのトリックについては満足で、段々と謎が解明されていく様子はページをめくる手が止められなかった。&#xA;上巻はカササギ殺人事件の様子が描かれており、下巻ではカササギ殺人事件を書いた人が殺されるミステリーだった。&#xA;カササギ殺人事件は、ある村にある屋敷で働く人と主が死ぬ事件を追い、後半では著者が残した謎を追う。&lt;/p&gt;&#xA;&lt;p&gt;下巻の後半に両方の事件のトリックが明かされた構成になっていた。&#xA;上巻の謎の種明かしはされずに、下巻で新しい謎の話が始まるから、下巻の序盤はげんなりした。&#xA;でも、下巻にさりげなく上巻の登場人物の名前を出しておくことで、ちゃんと思い出せるようになっていた気がする。&#xA;このお陰で、「何の話だったっけ？」とならずに済んだから、両方のミステリーを楽しめた。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models</title>
      <link>http://localhost:1313/post/paper/20260119093545-meta_tool_unleash_open_world_function_calling_capabilities_of_general_purpose_large_language_models/</link>
      <pubDate>Mon, 19 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260119093545-meta_tool_unleash_open_world_function_calling_capabilities_of_general_purpose_large_language_models/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.acl-long.1481/&#34;&gt;Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL2025 main&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プロンプトにツール情報が含まれない時、LLMの仮説生成+埋め込み検索が効果的である&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMと外部ツールの連携をするためのフレームワークを提案する&lt;/li&gt;&#xA;&lt;li&gt;外部ツールと連携する時にプロンプトに外部ツールの情報が与えられないケースを想定している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プロンプトにユーザーの指示が含まれるということは、ユーザーが事前に使用できるツールを知っている必要がある&#xA;&lt;ul&gt;&#xA;&lt;li&gt;この状況は、LLMの性能が一定の範囲しか発揮されないため、に制限をかけていることになる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;そのため、ユーザーの指示に応じてツールを選択し、呼び出す必要がある&#xA;&lt;ul&gt;&#xA;&lt;li&gt;これを、オープンワールドファンクションコーリングと呼んでいる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの推論のためのフレームワークと、学習と評価のためのデータセットを構築した&lt;/li&gt;&#xA;&lt;li&gt;推論のフレームワークには、hypothesize(仮説生成)-retrieve(検索)-invoke(呼び出し)フレームワークとしている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hypothesize(仮説生成)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMがユーザーの指示から、必要なツールの要件や引数を推論する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Retrieve(検索)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;テキスト埋め込みモデルを使用した検索システムを採用している&lt;/li&gt;&#xA;&lt;li&gt;推論したツール要件や引数を埋め込み表現に変換し、 類似度を計算している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Invoke(呼び出し)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ツールに対するクエリを生成する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;データセットには、既存のデータセットをオープンワールド形式に拡張するための方法を提案している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;拡張として、データセット内で呼び出されているツールをLLMで類似の形式に変換している&lt;/li&gt;&#xA;&lt;li&gt;変換後のツール呼び出しについて、推論プロセスを生成する&lt;/li&gt;&#xA;&lt;li&gt;この生成した一連のデータをルールベースやLLMベースの方法により評価する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;simpleタスクとhardタスクがあり、それぞれについてLLMを評価した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;hardは、拡張したツール呼び出しや、呼び出しの回数が多いデータが含まれる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;評価の結果、学習したモデルがGPT-4oやオープンソースモデルよりも性能が良いことが分かった&lt;/li&gt;&#xA;&lt;li&gt;検索システムは、キーワードベースの手法と比較していて、提案手法の方がhard設定で良い性能であった。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;シンプルな設定では、ますおこまで差がでないように見える&lt;/li&gt;&#xA;&lt;li&gt;埋め込みベースの他のモデルと比較しなくて良いのだろうか？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;仮説生成がどれだけ効くのか気になる&lt;/li&gt;&#xA;&lt;li&gt;埋め込みベースの検索が効くのは分かるが、ベースラインが弱いのでは？&#xA;&lt;ul&gt;&#xA;&lt;li&gt;他の良さそうな方法は思いつかないけど&lt;/li&gt;&#xA;&lt;li&gt;ツール呼び出しならではの検索システムとか考えることができそう&lt;/li&gt;&#xA;&lt;li&gt;引数の型は大きな制約の一つになると思う&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>ToolACE: Winning the Points of LLM Function Calling</title>
      <link>http://localhost:1313/post/paper/20260119105549-toolace_winning_the_points_of_llm_function_calling/</link>
      <pubDate>Mon, 19 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260119105549-toolace_winning_the_points_of_llm_function_calling/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=8EB8k6DdCU&#34;&gt;ToolACE: Winning the Points of LLM Function Calling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ICLR 2025&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;人工APIをLLMが生成することで、LLMのツール呼び出しの性能を向上させることができる。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ツール呼び出しタスクの学習に使用するためのデータを生成するパイプラインを作成する&lt;/li&gt;&#xA;&lt;li&gt;マルチターンなどの複雑なタスクが必要な状況を想定する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;現実世界におけるツール呼び出しは複雑である&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ユーザーの指示の多様さや曖昧さ、zero-shot推論だけではなく、複数のツールの組み合わせが必要なケースがある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データ生成パイプラインとして以下の3ステップを提案した&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ツール生成&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Tool Self-Evolution Synthesisという方法を提案した&lt;/li&gt;&#xA;&lt;li&gt;最初に、事前学習用のデータからAPIの情報を抽出する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;人工APIの分類を指しているのかも？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;作成したノードを基に、APIが対応している範囲を調査する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;フィードバックをしていると考えて良さそう&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;フィードバックを基に、APIの仕様を改善する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;対話生成&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;user、assistant、toolのそれぞれのroleをLLMが生成する&lt;/li&gt;&#xA;&lt;li&gt;対話の複雑さを評価するために、コンテキストから次のステップのトークンが生成される確率の平均値を使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;検証&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ルールベースの評価とLLMによる評価によるデータセットの評価が適用される&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;LLMの評価は、ハルシネーションの確認、レスポンスの一貫性、ツール呼び出しの適切さで評価される&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;8Bモデルを学習し、BFCLとAPI-Bankで評価した&lt;/li&gt;&#xA;&lt;li&gt;BFCLの評価では、オープンソースのモデルよりも良い性能であった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;xLAMよりも性能が良く、GPT-4oの一部のモデルよりも良い&lt;/li&gt;&#xA;&lt;li&gt;特に、Non-liveが強くなっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;API-Bankにおいても同様の傾向がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;</description>
    </item>
    <item>
      <title>ファラオの密室</title>
      <link>http://localhost:1313/post/book/20260117103018-%E3%83%95%E3%82%A1%E3%83%A9%E3%82%AA%E3%81%AE%E5%AF%86%E5%AE%A4/</link>
      <pubDate>Sat, 17 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260117103018-%E3%83%95%E3%82%A1%E3%83%A9%E3%82%AA%E3%81%AE%E5%AF%86%E5%AE%A4/</guid>
      <description>&lt;p&gt;ファラオの密室を読んだ。&#xA;ある事件で死んだセティと呼ばれる神官が訳あって復活し、自分の死に関する謎を解くミステリー。&#xA;本の中には、大きく3つの謎がある。&#xA;一つ目は、神官セティはなぜ復活したのか？という謎である。&#xA;二つ目は、先王のミイラは何故棺の中に無かったのか？&#xA;三つ目は、ピラミッドの建築のための資材の移動が遅いのは何故か？というものであった。&#xA;二つ目の謎については、プロローグで事件が起きる。&#xA;そして、神官セティが冥界で目を覚まして小説が始まる。&lt;/p&gt;&#xA;&lt;p&gt;ミステリーとしても面白かったし、エジプト社会の描写も楽しめた。&#xA;それぞれの謎のトリックについて、そうかという納得感があった。&#xA;背景にも、エジプト社会固有の事情が背景になっていて、エジプトという世界が活かされていた。&#xA;オシリスやアヌビスなどの多神教の教えを、アテンという唯一神に先王は変えようとした。&#xA;この宗教対立という実際にあった出来事を事件の背景に上手く導入されていたと思う。&#xA;宗教観の理解については、エジプト人ではない奴隷に質問させることで噛み砕かれて、うまかった。&lt;/p&gt;&#xA;&lt;p&gt;エピローグでは、セティ本人の真実が明かされる。。。!&#xA;これは、おまけと言って良いのか分かんないけど、小説の締めとして終わった感じがした。&lt;/p&gt;</description>
    </item>
    <item>
      <title>API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs</title>
      <link>http://localhost:1313/post/paper/20260115103448-api_bank_a_comprehensive_benchmark_for_tool_augmented_llms/</link>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260115103448-api_bank_a_comprehensive_benchmark_for_tool_augmented_llms/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2023.emnlp-main.187/&#34;&gt;API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;EMNLP 2023 main&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Tool Callingタスクのデータの構築において、多様なドメインを含めることが重要である。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが外部ツールを使用する能力を評価するためのベンチマークを構築した&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの性能は学習データに依存するため、最新の情報を応答に反映することができない&lt;/li&gt;&#xA;&lt;li&gt;外部ツールを使用することで、最新の情報に対応することができるが、LLMの外部ツールの性能評価はされていない&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMのAPI呼び出し性能を評価するためのベンチマークデータセットと学習データを構築した&lt;/li&gt;&#xA;&lt;li&gt;ベンチマークデータセットの構築&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの能力を評価する上で、APIの呼び出し回数と呼び出すことのできるAPIの数を基準にタスクを構築&lt;/li&gt;&#xA;&lt;li&gt;タスクの分類は以下の三種類&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Call : 一回以上のAPI呼び出しで、APIの数が少ない&lt;/li&gt;&#xA;&lt;li&gt;Retrieve+Call : 一回のAPI呼び出しで、APIの数が多い。LLMには使用できるAPIが与えられない。&lt;/li&gt;&#xA;&lt;li&gt;Plan+Retrieve+Call : 複数回の呼び出しで、APIの数が多い。LLMには使用できるAPIが与えられない&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ベンチマークに使用されるAPIは、実際に実装している(おそらく架空のAPI)&lt;/li&gt;&#xA;&lt;li&gt;アノテーションは人手で行うようにしている&lt;/li&gt;&#xA;&lt;li&gt;評価指標は、LLMが作成したクエリの正解率とAPIの応答を基に生成した文章のROUGE-Lスコアを使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;学習データセットの構築&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データセットはLLMを用いて作成された合成データセットを用いる&lt;/li&gt;&#xA;&lt;li&gt;生成は五つのLLMが独立してデータを生成する&#xA;&lt;ol&gt;&#xA;&lt;li&gt;ヘルスケアなどのデータのドメインを指定する&lt;/li&gt;&#xA;&lt;li&gt;ドメインを基にAPIを合成する、合成時には実データを例として与えている&lt;/li&gt;&#xA;&lt;li&gt;合成されたAPIをランダムサンプリングし、クエリを作成する&lt;/li&gt;&#xA;&lt;li&gt;APIのレスポンスを生成する&lt;/li&gt;&#xA;&lt;li&gt;データセットに沿う内容になっているか、評価し、フィルターする&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lynxというモデルを提案手法により作成されたデータセットを用いて評価した&lt;/li&gt;&#xA;&lt;li&gt;学習することで、LLMの性能が向上することが分かった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;同じようなデータになっているなら、当然な気がする&lt;/li&gt;&#xA;&lt;li&gt;エラーの傾向として、学習前はAPIの呼び出しが無いケースが多いが、学習後はAPIの関数名の間違えているケースに変化した&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ベンチマークについては、GPTなどのモデルと比較すると、Callが一番簡単で、Plan+Retrieve+Callが難しい傾向がある&lt;/li&gt;&#xA;&lt;li&gt;ToolAlpacaと比較すると、少ないデータで同等の性能が得られた&#xA;&lt;ul&gt;&#xA;&lt;li&gt;高品質なデータであると言えるのか？評価データによって結果が変わりそう&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ベンチマークと学習データを同じような方針で作成したら、評価結果が良くなるのは当たり前ではと思った&lt;/li&gt;&#xA;&lt;li&gt;手法自体は参考になりそう&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>有罪、とAIは告げた</title>
      <link>http://localhost:1313/post/book/20260114185025-%E6%9C%89%E7%BD%AA_%E3%81%A8ai%E3%81%AF%E5%91%8A%E3%81%92%E3%81%9F/</link>
      <pubDate>Wed, 14 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260114185025-%E6%9C%89%E7%BD%AA_%E3%81%A8ai%E3%81%AF%E5%91%8A%E3%81%92%E3%81%9F/</guid>
      <description>&lt;p&gt;中山七里の「有罪、とAIは告げた」を読んだ。&#xA;東京地裁を舞台に、人間の裁判官と同じ判決を出力できるAI裁判官「法神」の判決を巡るミステリー。&#xA;最初は、AI裁判官の導入や性能評価の話をしている。&#xA;この「法神」が、ある殺人事件において死刑を宣告する所から物語が大きく動き出す。&lt;/p&gt;&#xA;&lt;p&gt;上手く言語化できないけど、すごくもやもやした。&#xA;AIに流される人やAIの営業をする人の行動や言動にムカついただけな気がしてきた。&#xA;AIは中国との技術交流の名目で持ち込まれていて、「法神」にはある秘密がある。&#xA;この秘密については現実味がある程度あると思うのだけど、露悪的過ぎのようにも感じた。&lt;/p&gt;&#xA;&lt;p&gt;AI時代において、人間の仕事は責任を取ることであるということがメッセージの中核にあると思う。&#xA;これ、柞刈湯葉の「未来職安」の話と同じだ。&#xA;場所が裁判所か、架空の職業かという違いくらいしか無いんじゃないか？&lt;/p&gt;</description>
    </item>
    <item>
      <title>文化系のための野球入門</title>
      <link>http://localhost:1313/post/book/20260113191528-%E6%96%87%E5%8C%96%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E9%87%8E%E7%90%83%E5%85%A5%E9%96%80/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260113191528-%E6%96%87%E5%8C%96%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E9%87%8E%E7%90%83%E5%85%A5%E9%96%80/</guid>
      <description>&lt;p&gt;文化系のための野球入門を読んだ。&#xA;日本に野球が持ち込まれてから、現代までどのような変遷を辿ってきたのかを解説しつつ、批評している本だった。&lt;/p&gt;&#xA;&lt;p&gt;野球という一つの題材を、ジェンダーや歴史、社会など色々な側面から論じていて、面白かった。&#xA;野球が元々サブカル的なものであったことや、甲子園が成立に至るまでの経緯など、知らなかったことが多かった。&#xA;甲子園は、明るいニュースを生み出す必要があって企画された側面があったことや、球場のスタンド？に入ることができる女子が1人までという規定があるというのは知らなかった。&#xA;この規定については、甲子園の伝統とやらを守るという本音が隠れているという指摘など、ジェンダー論などにも踏み込んでいて、そこまで分析できるんだという視点が新しく得られた。&lt;/p&gt;&#xA;&lt;p&gt;野球だけではなく、体育や他のスポーツについて論じている点も学びになった。&#xA;他のスポーツを同じように分析してみると、どのような結論が出てくるのか興味がある。&#xA;野球と比較されがちなサッカーについてはどうなんだろうか。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AgentTuning: Enabling Generalized Agent Abilities for LLMs</title>
      <link>http://localhost:1313/post/paper/20260112102806-agenttuning_enabling_generalized_agent_abilities_for_llms/</link>
      <pubDate>Mon, 12 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260112102806-agenttuning_enabling_generalized_agent_abilities_for_llms/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2024.findings-acl.181/&#34;&gt;AgentTuning: Enabling Generalized Agent Abilities for LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL 2024 findings&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;NLPとエージェントタスクの損失関数の重み付き和を使うことで、NLPタスクの性能を維持しつつ、エージェントタスクの性能が向上する。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMのエージェント性能を向上させるためのデータセット構築、学習パイプラインを提案した&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;既存のエージェントタスクの手法はプロンプトや特定のエージェントタスク偏っている&lt;/li&gt;&#xA;&lt;li&gt;NLPにおけるタスクの能力を維持しつつ、エージェントタスクの能力を向上する必要がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データセットの構築には、self-instrcutを使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;既存のデータセットにあるユーザーとエージェントのインタラクションの続きを、GPT-4により生成する&lt;/li&gt;&#xA;&lt;li&gt;最終的なエージェントの行動の結果は報酬として評価される&#xA;&lt;ul&gt;&#xA;&lt;li&gt;この報酬は、タスク毎に設計されていて、報酬の値を基にフィルタリングをしている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;学習に使用するデータセットは、上記の方法で構築されたデータセットと指示学習用のものの二つを用いる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;損失関数には、それぞれのデータセットに対するクロスエントロピーの重み付け和を使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;held-in、heol-outなタスクにおいてGPT-4や3.5と同等の性能を示した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;これが公平な比較になっているかは分からない&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;公開されているLlamaよりも基本的なエラーが減少している&lt;/li&gt;&#xA;&lt;li&gt;学習には、エージェントタスクだけではなく、指示学習用のデータも混ぜた方が汎化性能が向上する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;出力を見た感じでは、想定しているエージェントタスクと違うのかも？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;損失関数を混ぜることと、継続学習でどちらが有効なのか気になった&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Lemur: Harmonizing Natural Language and Code for Language Agents</title>
      <link>http://localhost:1313/post/paper/20260112094443-lemur_harmonizing_natural_language_and_code_for_language_agents/</link>
      <pubDate>Mon, 12 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260112094443-lemur_harmonizing_natural_language_and_code_for_language_agents/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=hNhwSmtXRh&#34;&gt;Lemur: Harmonizing Natural Language and Code for Language Agents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ICLR Spotlight&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;事前学習にコーディングタスクを混ぜることで、実用的なLLMを学習することができる。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一つのLLMで、言語とプログラミングの能力をバランス良く学習すること&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの実環境用のインタラクションにおいて、APIを活用する必要がある&#xA;&lt;ul&gt;&#xA;&lt;li&gt;チャット機能や推論だけではなく、プログラムを適切に構築する能力も必要になっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ChatGPTなどのClosedなLLMでは、チャット機能とプログラムの両方を実現できている&lt;/li&gt;&#xA;&lt;li&gt;一方で、Llamaなどのモデルは、それぞれのタスク専用のLLMを公開するに留まっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;事前学習とインストラクションチューニングに分けて学習する。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;事前学習では、コーディングタスクとテキストの割合を10:1にして学習している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習に使用したプログラムはThe Stackデータセットを活用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;インストラクションチューニングは既存の複数のデータセットを混ぜて使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ここのデータはテキストのみ&lt;/li&gt;&#xA;&lt;li&gt;そこまで工夫している点ではないのかも？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;事前学習にコーディングタスクを混ぜて学習し、インストラクションチューニングを適用することで、自然言語を対象とした推論能力を維持しつつ、コーディングタスクにおける性能が向上している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プログラミングだけではなく、APIを使用した推論についても性能が向上している。&lt;/li&gt;&#xA;&lt;li&gt;事前学習が有効であると言えるのかもしれない。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;査読でも指摘されていたけど、事前学習のタスクの割合がどれくらい有効なのか分からない&#xA;&lt;ul&gt;&#xA;&lt;li&gt;著者らは継続学習して、調べているらしい&lt;/li&gt;&#xA;&lt;li&gt;この辺のバランスを良い感じに調整できたら熱い気がする&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Toolformer: Language Models Can Teach Themselves to Use Tools</title>
      <link>http://localhost:1313/post/paper/20260112133140-toolformer_language_models_can_teach_themselves_to_use_tools/</link>
      <pubDate>Mon, 12 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20260112133140-toolformer_language_models_can_teach_themselves_to_use_tools/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html&#34;&gt;Toolformer: Language Models Can Teach Themselves to Use Tools&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;NeurIPS 2023&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データ拡張にAPIを用いることで、下流タスクにおける性能が向上する。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;自己教師有り学習により、外部ツールをLLMが使用する方法を学習する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価と違う点があるから、読み違えているかも&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;テキストデータから、Tool Callingデータセットを作成する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;既存の手法は、大規模な人手アノテーションが必要であることや、特定のタスクのみを対象としている&lt;/li&gt;&#xA;&lt;li&gt;そのため、学習したLLMの応用先が限られるという課題がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データ拡張にはテキストデータを用いる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;疑似APIをLLMを用いて生成する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;疑似APIの形式は &lt;code&gt;QA(c)-&amp;gt; r&lt;/code&gt; のような感じ&lt;/li&gt;&#xA;&lt;li&gt;使用するタスクとしては、QAや計算問題を用いている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;生成された疑似APIを実行する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;実行は、LLMやPythonなどの環境ですることを想定している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;フィルタリングには、重み付きクロスエントロピーを基準として用いている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;生成されたトークンの損失と、何も生成されなかった時の損失の差が閾値よりも大きい時、データセットに含むようにしている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;推論時には、 &lt;code&gt;-&amp;gt;&lt;/code&gt; トークンが生成されるまでデコーディングを行う&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ここでAPIの呼び出しが入るため、APIの結果を挿入して、デコーディングを再開する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;QAや数学タスクにおける性能が向上した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;下流タスクにおける性能が向上している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Tool Callの評価が無いのが気になる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目的がTool Callingの性能向上ではなく、Tool Callingを通した性能向上になるのかも&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価のやり方が適切であるかどうか分からない&#xA;&lt;ul&gt;&#xA;&lt;li&gt;API callを実際にしているのか？&lt;/li&gt;&#xA;&lt;li&gt;下流タスクにおいて外部ツールを呼び出せるなら性能の向上は必然では？とも思う。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;このデータ拡張のやり方は面白いと思った。&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>都市伝説解体センター</title>
      <link>http://localhost:1313/post/game/20260112232718-%E9%83%BD%E5%B8%82%E4%BC%9D%E8%AA%AC%E8%A7%A3%E4%BD%93%E3%82%BB%E3%83%B3%E3%82%BF%E3%83%BC/</link>
      <pubDate>Mon, 12 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/game/20260112232718-%E9%83%BD%E5%B8%82%E4%BC%9D%E8%AA%AC%E8%A7%A3%E4%BD%93%E3%82%BB%E3%83%B3%E3%82%BF%E3%83%BC/</guid>
      <description>&lt;p&gt;都市伝説解体センターをクリアした。&#xA;主人公は、不思議な力を持つピュアな大学生。&#xA;この主人公が、都市伝説解体センターという機関で様々な事件や謎を解決していくノベルゲームだ。&lt;/p&gt;&#xA;&lt;p&gt;序盤は退屈な感じがしていたけど、後半の展開は見事だった。&#xA;SNSと通した調査があるの何？って思いながら進めていたのだが、これにも意味があるので、心を折らずに最後までやって欲しい。&#xA;普通の事件を都市伝説と関連付けながら解決していくだけのゲームだと思っていたら、最後に怒涛の伏線回収があり、とても良かった。&#xA;全ての謎に理由があるというのがすっきりした。&#xA;全部で6章あり、最後の事件は全ての謎が繋り、事件の謎や能力の理由が明かされた。&#xA;最後の展開は完全に予想外だった。&lt;/p&gt;&#xA;&lt;p&gt;ストーリーも良かったけど、ピクセルをベースにしたデザインが気に入った。&#xA;あざみやジャスミンの表情や動いている様子が刺さった。&#xA;個人的にピクセルアートが好きなのだが、それを上手くアニメーションに落とし込めているように見えた。&lt;/p&gt;&#xA;&lt;p&gt;後で、全部見返すと、気付いていない伏線がたくさんありそうなとても良いゲームだった。&#xA;疑問としては、センター長の電話がどうなっているのか分からなかった。&#xA;ノベライズして欲しいなあ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>マイクロスパイ・アンサンブル</title>
      <link>http://localhost:1313/post/book/20260107224725-%E3%83%9E%E3%82%A4%E3%82%AF%E3%83%AD%E3%82%B9%E3%83%91%E3%82%A4_%E3%82%A2%E3%83%B3%E3%82%B5%E3%83%B3%E3%83%96%E3%83%AB/</link>
      <pubDate>Wed, 07 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260107224725-%E3%83%9E%E3%82%A4%E3%82%AF%E3%83%AD%E3%82%B9%E3%83%91%E3%82%A4_%E3%82%A2%E3%83%B3%E3%82%B5%E3%83%B3%E3%83%96%E3%83%AB/</guid>
      <description>&lt;p&gt;伊坂幸太郎のマイクロスパイ・アンサンブルを読んだ。&#xA;猪苗代湖で行なわれているロックフェスにおいて、毎年配布される冊子で連載されているものを文庫化したらしい。&#xA;これにちなんで、小説の舞台は猪苗代湖が中心になっている&lt;/p&gt;&#xA;&lt;p&gt;話の内容としては、ある機関のスパイと社会人の物語。&#xA;二人が住んでいる世界は別物のように書かれているが、実は繋っている。&#xA;どちらかが取った行動が、どちらかの世界に影響している様子が面白かった。&#xA;社会人の世界において、社会人の友達が猪苗代湖で無くしたものが、スパイの世界では宝物として引き上げられて、最終的に見つかる所や、社会人の世界で地面に置いたコップがスパイの命を助けたりしている。&#xA;この奇妙な偶然の一致が話を進めていく様子は、何か暖かい気持ちになった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>夜がどれほど暗くても</title>
      <link>http://localhost:1313/post/book/20260104175930-%E5%A4%9C%E3%81%8C%E3%81%A9%E3%82%8C%E3%81%BB%E3%81%A9%E6%9A%97%E3%81%8F%E3%81%A6%E3%82%82/</link>
      <pubDate>Mon, 05 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260104175930-%E5%A4%9C%E3%81%8C%E3%81%A9%E3%82%8C%E3%81%BB%E3%81%A9%E6%9A%97%E3%81%8F%E3%81%A6%E3%82%82/</guid>
      <description>&lt;p&gt;中山七里の「夜がどれほど暗くても」を読んだ。&#xA;とある週刊誌の副編集長の息子が、ストーカー行為をし、無理心中したという疑いがあるという所から物語が始まる。&#xA;ここから、副編集長の身の周りで起きる様々な出来事がきつかった。&#xA;本当にありそうな所がとてもエグかったな。&lt;/p&gt;&#xA;&lt;p&gt;ネットで叩かれるだけではなく、様々な嫌がらせを受ける。&#xA;特に被害者の遺族から襲われてから、大きく物語が動いていき、一気に読ませられた。&#xA;殺人事件のトリックというよりも、副編集長の心の動きを追うというような楽しみ方ができて、ある意味新鮮だった。&#xA;さすがの筆力だった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>過疎ビジネス</title>
      <link>http://localhost:1313/post/book/20260104104718-%E9%81%8E%E7%96%8E%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9/</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260104104718-%E9%81%8E%E7%96%8E%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9/</guid>
      <description>&lt;p&gt;過疎ビジネスを読んだ。&#xA;福島県国見町で救急車のリース事業が始まることになった。&#xA;財源は企業版のふるさと納税が当てられている。&#xA;このビジネスから、「誰も」注目しない過疎地域に巣喰うコンサルや行政の実態を暴いた本である。&lt;/p&gt;&#xA;&lt;p&gt;著者は新聞社の記者で、新聞や経済誌で書いた内容を基に書かれている。&#xA;企業や人名はほとんどが実名で書かれていて、著者の気概を感じた。&#xA;実際にコンサルから有名弁護士事務所を通して、起訴するという文面を受け取りながら、これは中々だった。&lt;/p&gt;&#xA;&lt;p&gt;コンサルや首長のせいにして解決という話ではない。&#xA;国の政策が大本になるのだが、選挙により選ばれた首長やスキームを考えついたコンサルへの監視について機能していないことも一因になる。&#xA;説教臭いけど、興味を持つことが大事なのではないかと思った。&#xA;全部に興味を持つのは大変だから、何か軸を定めて判断できるようにしてきたい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ネット怪談の民俗学</title>
      <link>http://localhost:1313/post/book/20260103105046-%E3%83%8D%E3%83%83%E3%83%88%E6%80%AA%E8%AB%87%E3%81%AE%E6%B0%91%E4%BF%97%E5%AD%A6/</link>
      <pubDate>Sat, 03 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260103105046-%E3%83%8D%E3%83%83%E3%83%88%E6%80%AA%E8%AB%87%E3%81%AE%E6%B0%91%E4%BF%97%E5%AD%A6/</guid>
      <description>&lt;p&gt;ネット怪談の民族学を読んだ。&#xA;「くねくね」や「きさらぎ駅」などの2チャンネルのスレッドで話題になった怪談を民族学的に分析している本だった。&lt;/p&gt;&#xA;&lt;p&gt;本の中で、様々なネット怪談の具体例を話の流れをスレのリアクションと共に説明されていて分かりやすかった。&#xA;ある話について、他の人も同じような体験があることや話を知っているというリアクションがあるのは興味深かった。&#xA;ただ、僕がネット怪談にあまり触れてこなかったからか、怪談の話はほとんど知らなかった。&#xA;どれか一つでも、話の流れや内容を知っていれば、「そんな話あったな〜」というような楽しみ方ができると思う。&#xA;これに加えて分析が加わるので、より内容を憶えていられるような気がした。&lt;/p&gt;&#xA;&lt;p&gt;面白かったと思った点は二つある。&#xA;一つは、田舎の因習系のホラーコンテンツについては、偏見や差別があるという指摘がされているという点である。&#xA;最近はこのようなコンテンツは作られていないらしい。&#xA;この話は、暗黙的なバイアスが自分の中にあることを明らかにされて、はっとした。&#xA;加えて、民族学者が田舎に調査に行き、世間に公表することで、いわゆる遅れた文化が知らるようになった背景を知ると何とも言えない気持ちになった。&lt;/p&gt;&#xA;&lt;p&gt;もう一つは、怪談が作られる過程を分析している所だ。&#xA;ある画像やテキストから、勝手に物語を追加してく過程が共通していた。&#xA;日本だけではなく、スレンダーマンなどの外国にも見られるというのが興味深かった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>虚の伽藍</title>
      <link>http://localhost:1313/post/book/20260102090945-%E8%99%9A%E3%81%AE%E4%BC%BD%E8%97%8D/</link>
      <pubDate>Fri, 02 Jan 2026 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20260102090945-%E8%99%9A%E3%81%AE%E4%BC%BD%E8%97%8D/</guid>
      <description>&lt;p&gt;虚の伽藍を読んだ。&#xA;いやー、面白かった。&#xA;400ページくらいあるが、一気に読んでしまった。&lt;/p&gt;&#xA;&lt;p&gt;主人公は、日本仏教の最大宗派で働く僧侶の陵玄。&#xA;この僧侶が、京都の土地に関する書類が不足している所から話が始まる。&#xA;同時に京都闇社会と繋っていく。。。という内容の小説である。&lt;/p&gt;&#xA;&lt;p&gt;第一部と第二部に分かれていて、一部では陵玄が組織の不正を暴き、出世する話だ。た。&#xA;二部では、宗派内の権力争いの様子が書かれている。&lt;/p&gt;&#xA;&lt;p&gt;陵玄は、仏のためと言いながら、様々な悪事に手を染めていく様子にぞっとした。&#xA;二部の権力争いの内容としては、選挙の票集めの事だ。&#xA;この票集めの道中で、一部で繋った闇社会の人間を易々と切り捨てていく。&#xA;ほとんどの人が死んでいく様子を見ながら、ここまで人が変わるのかと思った。&#xA;選挙に陵玄は勝つのだが、選挙の一番のライバルである親友を自殺に追い込むのは見ていられなかった。&#xA;この一部と二部の陵玄の豹変っぷりが味わえてとても良かった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Personalized Text Generation with Contrastive Activation Steering</title>
      <link>http://localhost:1313/post/paper/20251225101002-personalized_text_generation_with_contrastive_activation_steering/</link>
      <pubDate>Thu, 25 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251225101002-personalized_text_generation_with_contrastive_activation_steering/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.acl-long.353/&#34;&gt;Personalized Text Generation with Contrastive Activation Steering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL2025 long&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが生成する応答を人間が書いた応答を比較することで、LLMが生成する文章のスタイルを合わせることができる。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの内部表現に介入して、生成する文章を個人に最適化すること&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ユーザー毎に最適化されたテキストを生成する需要が高まっている&lt;/li&gt;&#xA;&lt;li&gt;既存の手法はRAGやPEFTによる手法が注目されている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;これらの手法は計算コストが高いことや、ユーザー特有の言い回しに影響されやすい&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの隠れ層に介入することで、個人に最適化された文章を生成すること&lt;/li&gt;&#xA;&lt;li&gt;前提として、あるユーザーのプロンプトとそれに対する応答がある&lt;/li&gt;&#xA;&lt;li&gt;最初に、LLMはプロンプトに対する応答を生成する&lt;/li&gt;&#xA;&lt;li&gt;プロンプトと応答を繋げた文章の最終トークンに該当する特徴量を使って介入する方向の計算をする&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ユーザーの応答を繋げた場合の特徴量をポジティブ、LLMの応答を繋げた場合の特徴量をネガティブとしている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;こうすることで、今のLLMがその人に合わせるためにどれくらい介入すれば良いか計算できる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;方向の計算には、様々な方法を使用している&lt;/li&gt;&#xA;&lt;li&gt;PCAとか、Mean Differenceなどなど&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ここで計算したベクトルを用いて介入する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;個別最適化ベンチマークのLaMPで評価した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;短文を評価するものと長文を評価するものの二つがある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;提案手法は、RAGやPEFTの手法よりも良い性能を示している&lt;/li&gt;&#xA;&lt;li&gt;介入量により性能が大きく変わる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提案手法により推定された介入ベクトルにおいて正の方向に介入するとユーザーのスタイルを反映しやすくなるが、負の方向にするとスタイルが関係無くなってしまう&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;実験のスタイルベクトルの計算には何を使用したのだろうか？&#xA;&lt;ul&gt;&#xA;&lt;li&gt;スタイルベクトルの計算方法によって性能が変わったりするのかな&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>よい対立・悪い対立</title>
      <link>http://localhost:1313/post/book/20251225223734-%E3%82%88%E3%81%84%E5%AF%BE%E7%AB%8B_%E6%82%AA%E3%81%84%E5%AF%BE%E7%AB%8B/</link>
      <pubDate>Thu, 25 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20251225223734-%E3%82%88%E3%81%84%E5%AF%BE%E7%AB%8B_%E6%82%AA%E3%81%84%E5%AF%BE%E7%AB%8B/</guid>
      <description>&lt;p&gt;よい対立・悪い対立を呼んだ。&#xA;よい対立は、健全な対立と呼ばれている。&#xA;本の中には以下のように書かれている。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;自らを守り、互いを理解し合い、向上してくために欠かせないもの、それが健全な対立だ。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;これに対して、悪い対立は不健全な対立と呼ばれ、本の中では以下のように書かれていた。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;「善と悪」「わたしたちと彼ら」といった、相反する関係が明確になった時に起こるのが不健全な対立だ。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;この二項対立的な構図は色々な所で見たことある気がした。&lt;/p&gt;&#xA;&lt;p&gt;悪い対立に落ちてしまっても、よい対立に戻ることができるようになる事例が紹介されていて希望が持てた。&#xA;でも、これを実践するため、これまでの言説や行動を変える必要がある。&#xA;周りの人々は、突然の本人の変化を止めようと説得してきたりしてきていた。&#xA;二つの異なる事例で、同じような行動を周りの人が取っていて「なるほどなあ」となった。&#xA;本当に、よい対立に戻ることの難しさを感じた。&lt;/p&gt;&#xA;&lt;p&gt;二項対立的に考えて、人にレッテルを貼る所があるので、気をつけていきたい。&#xA;そういう人に対して冷たく当たるのではなく、きちんと意見を交換できるような謙虚な姿勢を取れるようになりたい。&#xA;まずは、人の話をきちんと聞くことから始める。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention</title>
      <link>http://localhost:1313/post/paper/20251224102456-activation_steering_decoding_mitigating_hallucination_in_large_vision_language_models_through_bidirectional_hidden_state_intervention/</link>
      <pubDate>Wed, 24 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251224102456-activation_steering_decoding_mitigating_hallucination_in_large_vision_language_models_through_bidirectional_hidden_state_intervention/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.acl-long.634/&#34;&gt;Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL 2025&lt;/li&gt;&#xA;&lt;li&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;（1, 2文でまとめる）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Vison-Languageモデル(VLM)の内部表現に介入することで、ハルシネーションを防ぐこと&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ここでのハルシネーションは、画像に写っていない物体についてモデルが言及する現象を指す&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;VLMのハルシネーションを防ぐことは、実用上重要&lt;/li&gt;&#xA;&lt;li&gt;既存の手法はデータの品質や損失関数の工夫などでこれに対処してきた&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習に必要な計算コストが大きいため、実地に適応するために時間がかかる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;他の学習無しの手法では画像の優先度を上げるようにしているが、画像内のAttentionなどの特定の仮定に依存している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MSCOCOを使用して、VLMの中間表現をProbingする。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ハルシネーションをしているかどうかは、トークンがMSCOCOのクラスの単語がそれの類義語を含むかどうかで判定している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;介入するベクトルは、ハルシネーションが無いトークンの中間表現の平均ベクトルからハルシネーションしているトークンの中間表現の平均ベクトルを引いたベクトルを用いる&lt;/li&gt;&#xA;&lt;li&gt;文章の生成時には、正の方向と負の方向に介入した二つのモデルが生成するロジットを足したものを使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;介入する量は個別に設定している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ベンチマークにおける評価では、正解率とF1スコアが改善している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用するデータはハルシネーションのベンチマーク&lt;/li&gt;&#xA;&lt;li&gt;既存のハルシネーション対策をする手法よりも良くなっている&lt;/li&gt;&#xA;&lt;li&gt;既存の画像理解ベンチマークにおいても他の手法と同等の性能になっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;介入量毎の性能を見ると、正の方向への介入量はパフォーマンスに大きく影響する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ハイパラの量が増えているのは良いのか？&lt;/li&gt;&#xA;&lt;li&gt;著者らも言及しているが、カテゴリ名などはMSCOCOに依存している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;これ難しい問題だと思った&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Calibrating LLM Confidence by Probing Perturbed Representation Stability</title>
      <link>http://localhost:1313/post/paper/20251223094430-calibrating_llm_confidence_by_probing_perturbed_representation_stability/</link>
      <pubDate>Tue, 23 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251223094430-calibrating_llm_confidence_by_probing_perturbed_representation_stability/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.emnlp-main.530/&#34;&gt;Calibrating LLM Confidence by Probing Perturbed Representation Stability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;EMNLP 2025 main&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;対照学習を使用することで、LLMの特徴と応答の一致度が向上する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの内部表現と出力文章の一致度を揃えるようにモデルを調整すること&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが割り当てる確率には、間違いの応答に高い確率を割り当てるなどの課題がある&lt;/li&gt;&#xA;&lt;li&gt;正確な応答に高い確率を割り当てるために、内部表現を調整する手法では複数の好ましい特性に対応することが難しい&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;トークン単位でLLMの最終層に摂動を加える&#xA;&lt;ul&gt;&#xA;&lt;li&gt;勾配を使用して摂動を加える&lt;/li&gt;&#xA;&lt;li&gt;損失関数は隠れ層の状態から正解トークンを予測する確率のクロスエントロピーを使用している&lt;/li&gt;&#xA;&lt;li&gt;パラメータを更新する時と逆方向の勾配を摂動として加える&lt;/li&gt;&#xA;&lt;li&gt;摂動を加えた時のロジットを2.で使用する&lt;/li&gt;&#xA;&lt;li&gt;この摂動を加えるステップはS回行う&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;この摂動に影響のある特徴を抽出する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徴量はトークン毎に抽出する&lt;/li&gt;&#xA;&lt;li&gt;このでも特徴量とは、ロジットや勾配のL2ノルムなどを指す&lt;/li&gt;&#xA;&lt;li&gt;この特徴量に対して平均などの統計処理を加えた値を最終的な特徴量とする&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;この特徴量から確信度(確率のことか？)を予測する分類器を学習する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分類器は二つ用いる&lt;/li&gt;&#xA;&lt;li&gt;トークンの特徴量毎に正解、不正解を予測する分類器と文章単位で予測する分類器&#xA;&lt;ul&gt;&#xA;&lt;li&gt;文章単位で予測する分類器は、トークン単位の分類器が抽出した特徴量を連結した特徴量を使用して予測している&lt;/li&gt;&#xA;&lt;li&gt;このでの特徴量は、モデルの最終出力を指す&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;トークン単位の分類器はMLP、文章単位の分類器は畳み込みを使用している&lt;/li&gt;&#xA;&lt;li&gt;目的関数はmax-margin損失を使用する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;負例はロジットの値を基に決めている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価は選択問題を対象とした&lt;/li&gt;&#xA;&lt;li&gt;評価指標には、Expected Calibration ErrorとBarier Scoreを使用している&lt;/li&gt;&#xA;&lt;li&gt;分類問題においては、ECEが他の指標よりもよく改善している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;加えて、正解率などの指標も改善することが分かった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;生成タスクにおいても改善できることが分かった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;他のドメインにおける有効性が気になる&lt;/li&gt;&#xA;&lt;li&gt;最終層だけで有効だったのかな&#xA;&lt;ul&gt;&#xA;&lt;li&gt;他のレイヤーの効果も気になる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>イランの地下世界</title>
      <link>http://localhost:1313/post/book/20251221094009-%E3%82%A4%E3%83%A9%E3%83%B3%E3%81%AE%E5%9C%B0%E4%B8%8B%E4%B8%96%E7%95%8C/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20251221094009-%E3%82%A4%E3%83%A9%E3%83%B3%E3%81%AE%E5%9C%B0%E4%B8%8B%E4%B8%96%E7%95%8C/</guid>
      <description>&lt;p&gt;イランの地下世界を読んだ。&#xA;イランで生活している著者が一般市民の生活の様子やイスラム社会を描いている。&lt;/p&gt;&#xA;&lt;p&gt;中東情勢といえばきな臭い印象があるが、この本を読んで視点が変わった所か興味すら出てきた。&#xA;スカーフの話は面白かった。&#xA;ここで言うスカーフは、イスラム教の戒律において女性が身につけるための布である。&#xA;この布を公共の場で外すことで、イスラム社会やイラン政権などへの抵抗を示すこともできる。&#xA;それに対して、スカーフさえ着けてればイスラム社会で出世することができたりするらしい。&#xA;このような人達を著者は「イスラム・ヤクザ」と呼んでいて、面白かった。&lt;/p&gt;&#xA;&lt;p&gt;スカーフを巡る話だけでも十分にイランやイスラム社会への興味が向けられて良かった。&#xA;他にも、イスラム教で禁止されている酒や肉の話などがあった。&#xA;イランが多民族であることが関係していて、世界は単純ではないということを改めて実感できた。&lt;/p&gt;</description>
    </item>
    <item>
      <title>カウンセリングとは何か 変化するということ</title>
      <link>http://localhost:1313/post/book/20251209222259-%E3%82%AB%E3%82%A6%E3%83%B3%E3%82%BB%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B_%E5%A4%89%E5%8C%96%E3%81%99%E3%82%8B%E3%81%A8%E3%81%84%E3%81%86%E3%81%93%E3%81%A8/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20251209222259-%E3%82%AB%E3%82%A6%E3%83%B3%E3%82%BB%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B_%E5%A4%89%E5%8C%96%E3%81%99%E3%82%8B%E3%81%A8%E3%81%84%E3%81%86%E3%81%93%E3%81%A8/</guid>
      <description>&lt;p&gt;面白かった。&lt;/p&gt;&#xA;&lt;p&gt;この本を読む前は、カウンセリングについて話を傾聴する程度の印象しかなかった。&#xA;序盤に、カウンセリングについての説明が以下のようにされている。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;カウンセリングとは、心の問題に苦しんでいる人に対して、心理的に理解して、それに即して必要な心理学的介入を行う専門的な営みである。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;この文章が、本文中にあるカウンセリングの具体例や、説明を通してとてもよく理解できた気がする。&#xA;特に四章の冒険としてのカウンセリングのエピソードは、カウンセリングに専門知識が必要であることが実感できた。&lt;/p&gt;&#xA;&lt;p&gt;心の変化に二種類あると捉えているのは視点だった。&#xA;科学的な変化と文学的な変化の両方がある。&#xA;科学的な変化とは脳内物質の変化による心の変化、文学的な変化とは、過去に意味付けを行い物語ることで今を認識する事を通して心を変化させる。&#xA;科学的な変化は直感的に受け入れることができたけど、今でも文学的な変化について腹落ちして理解できているかは怪しい。&#xA;この変化を小説では描いているのでは？というような気もしてきて、色んな発見がある本だった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning to Reasson from Feedback as Test-Time</title>
      <link>http://localhost:1313/post/paper/20251128102014-learning_to_reasson_from_feedback_as_test_time/</link>
      <pubDate>Fri, 28 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251128102014-learning_to_reasson_from_feedback_as_test_time/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.acl-long.262/&#34;&gt;Learning to Reason from Feedback at Test-Time&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ACL 2025 Long&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;フィードバックを用いてモデルを更新することで、過去の推論結果を活かしつつ推論の性能が向上する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;テスト時におけるフィードバックからLLMを更新する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;テスト時において推論を行い、その結果を用いて再度推論するというタスクになる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;この時に、過去の経験を上手く活用してLLMを更することを目指す&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;従来の手法では、Sequential RevisionとParallel samplingがある&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sequential Revisionは、過去のトライアル結果をプロンプトに含める方法&lt;/li&gt;&#xA;&lt;li&gt;Parallel Samplingは過去の結果に関わらず、何度か予測する方法になる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Sequential Revisionはコンテキスト長が長くなりやすいため、計算コストが高くなりやすく位置バイアスの影響もある&lt;/li&gt;&#xA;&lt;li&gt;Parallel samplingは効率的であるが、過去のエラーを考慮しない課題がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;過去のトライアルよりも、モデルの重みに重点を置いた手法を提案いている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;損失関数と効率的なOptimizerを提案している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;LLMは問題に対する解答をすると、検証モデルが正解かどうかを判定する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不正解である場合、検証モデルは不正解であるという固定の文章を生成する&lt;/li&gt;&#xA;&lt;li&gt;追加のフィードバックとしてLLMが文章生成する&lt;/li&gt;&#xA;&lt;li&gt;これらの二つのフィードバックに対してクロスエントロピーが最小になるように学習を進める&lt;/li&gt;&#xA;&lt;li&gt;モデルのパラメータ内に過去の経験が保存されるという話&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Optimizerについてはよく分からなかった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;PEFTを参考にしたみたい。。。？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Parallel Samplingでは20GPU/hだったのに対して、提案手法では4GPU/hに改善された&lt;/li&gt;&#xA;&lt;li&gt;トライアルの回数毎に比較すると、提案手法は回数が増える程性能が良くなっている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;手法によっては、低下しているものもある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Optimizerの比較では、LoRAと比較して少ないパラメータで良い性能になっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sequential Samplingと提案手法の計算コストが違いすぎないか&lt;/li&gt;&#xA;&lt;li&gt;Optmizerの立ち位置が分からない&#xA;&lt;ul&gt;&#xA;&lt;li&gt;これ別の手法ではない？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Personalized LLM Decoding via Contrasting Personal Preference</title>
      <link>http://localhost:1313/post/paper/20251125105451-personalized_llm_decoding_via_contrasting_personal_preference/</link>
      <pubDate>Tue, 25 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251125105451-personalized_llm_decoding_via_contrasting_personal_preference/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.emnlp-main.1723/&#34;&gt;Personalized LLM Decoding via Contrasting Personal Preference&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DPOを基にした報酬を活用して文章のデコーディングや負例の選択をすることは、パーソナライズにおいて有効である&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが文章を生成する時に、ユーザーの意図を推定しながら文章を生成するようにする&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ユーザーの意図に沿う応答を生成することはLLMの実用上重要である&lt;/li&gt;&#xA;&lt;li&gt;現状は、プロンプトベースの方法とLoRAなどモデルのパラメータを更新する方法の二種類がある&lt;/li&gt;&#xA;&lt;li&gt;プロンプトベースの手法では、ユーザーのデータから学習することが無いため効果が限定的である課題がある&lt;/li&gt;&#xA;&lt;li&gt;パラメータを更新する手法では、破滅的忘却や計算コストの面から課題がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基本的にLoRAを想定した手法になっている&lt;/li&gt;&#xA;&lt;li&gt;文章のデコーディングには、報酬ベースの手法を使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;閾値より大きな確率のトークン集合を得る&lt;/li&gt;&#xA;&lt;li&gt;基モデルとLoRAを適用したモデルがそのトークンを生成する確率の比を報酬とする&lt;/li&gt;&#xA;&lt;li&gt;この報酬が最大になるトークンを選択してデコーディングする&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;モデルの学習には、DPOを使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データセットの構築のためには、LLMが生成したいくつかの例の中から上記の報酬が最も小さいものを負例としている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プロンプトベースの手法は、性能向上が限定的であること&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ベースモデルよりも悪くなることがある&lt;/li&gt;&#xA;&lt;li&gt;特に長文において性能が低下することが確認できた&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;提案手法は、学習ベースの手法よりも良いモデルが学習できていた&#xA;&lt;ul&gt;&#xA;&lt;li&gt;報酬ベースのデコーダとDPOの効果は同程度であった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall</title>
      <link>http://localhost:1313/post/paper/20251124095855-self_guided_function_calling_in_large_language_models_via_stepwise_experience_recall/</link>
      <pubDate>Mon, 24 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251124095855-self_guided_function_calling_in_large_language_models_via_stepwise_experience_recall/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.findings-emnlp.574/&#34;&gt;Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;EMNLP 2025 findings&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMのFunction Callingタスクのデータの拡張のためには、呼び出されているタスクの一致度なども入れると良い&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMを外部APIと連携するタスクであるFunction Callingの性能を向上するような学習する&lt;/li&gt;&#xA;&lt;li&gt;学習に使用するプロンプトに含める例を工夫する手法にしている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習データやモデルのパラメータ数を単に増やしても、実世界インタラクションは解決することができない&lt;/li&gt;&#xA;&lt;li&gt;既存のFunction Callingの学習手法は、具体例を手動で付与しているため大規模にしづらい課題がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;類似の例を取得するための方法として、以下の三種類の指標を用いる&#xA;&lt;ol&gt;&#xA;&lt;li&gt;ユーザーのクエリと軌跡の埋め込み表現の類似度&#xA;&lt;ul&gt;&#xA;&lt;li&gt;軌跡とは、ユーザーの入力と呼び出されたツールの応答を複数ステップ繰り返したものを指す&lt;/li&gt;&#xA;&lt;li&gt;類似度の指標には、正規化コサイン類似度を使用する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;呼び出しツールの一致度&#xA;&lt;ul&gt;&#xA;&lt;li&gt;実際に使用されているツールの一致度を使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;意図アラインメント&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用する意図は、事前に定義されているクラスに分類されている&lt;/li&gt;&#xA;&lt;li&gt;類似度の検索に使用する履歴が与えられた時に意図を何らかの方法で推定しているのかも？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;最終的な類似度は、これらの重み付け和になっている&lt;/li&gt;&#xA;&lt;li&gt;類似度を計測するためのデータ集合は新たな軌跡が得られた時に更新する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMでユーザーの意図が達成できたと分類された時にデータ集合に追加する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ToolQAやτ-benchによる評価では、既存手法よりも概ね良い性能であった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ベースライン手法はTool Augmented LLMらしい&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Ablation Studyでは、2と3の指標のどちらも重要っぽいことが示されている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ToolQAのEasyでは3を無くすとスコアが大きく下がり、Hardでは2を無くす時が大きくスコアが下がった&lt;/li&gt;&#xA;&lt;li&gt;全体的には3の影響度が大きそうだけど、これは良く分かんないなあ&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;p&gt;特になし&lt;/p&gt;</description>
    </item>
    <item>
      <title>AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders</title>
      <link>http://localhost:1313/post/paper/20251122130944-axbench_steering_llms_even_simple_baselines_outperform_sparse_autoencoders/</link>
      <pubDate>Sat, 22 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251122130944-axbench_steering_llms_even_simple_baselines_outperform_sparse_autoencoders/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=K2CckZjNy0&#34;&gt;AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ICML 2025&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;（1, 2文でまとめる）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの内部表現に介入する手法の評価をするためのベンチマークデータセットを構築した&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの内部表現に介入する様々な手法が提案されている。&lt;/li&gt;&#xA;&lt;li&gt;だが、統一したベンチマークが存在しないため公平な評価ができていないという課題がある。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Concept DetectionとModel Steeringの二つの指標を評価するためのデータセットを構築した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Concept Detectionはシンプルな分類問題&lt;/li&gt;&#xA;&lt;li&gt;Model Steeringは、生成した文章をLLMが評価するものになる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;データの用意のために、GPT-4oを使用したデータ拡張が行なわれている&lt;/li&gt;&#xA;&lt;li&gt;Concept Dataset Generation&#xA;&lt;ul&gt;&#xA;&lt;li&gt;データセットの形式はPreferenceデータセットと同じ形式になっている&lt;/li&gt;&#xA;&lt;li&gt;指示とポジティブなデータはLLMにより生成されている&lt;/li&gt;&#xA;&lt;li&gt;ネガティブなデータには、異なるコンセプトに属するレスポンスを使用している&lt;/li&gt;&#xA;&lt;li&gt;タスクの評価指標には、特定のレイヤーの各トークンの中間表現を用いて分類器が予測した確率の最大値を用いている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分類器の予測は[0-1]の一次元の出力になる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Model Steering&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価指標&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが応答を0、1、2のいずれかで評価する&lt;/li&gt;&#xA;&lt;li&gt;スコアは、Concept、Instructoin、Fluencyの3つを使用する&lt;/li&gt;&#xA;&lt;li&gt;最終スコアは、調和平均を使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;論文中で報告されているのは、特定のレイヤーにおけるスコアになっている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Model Steeringでは特定のレイヤーに介入した時のスコアになっている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Concept DetectionではProbeベースの手法が、SAEを使用する手法よりも良い性能であった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価指標は、AUROCを用いている&lt;/li&gt;&#xA;&lt;li&gt;特に、SAEはデータのバランスが悪いと性能が低下する傾向がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Model Steeringにおいては、SAEの方が良い性能であるがLoRAやSFTよりも性能が低い結果であった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Model Steeringのスコアにおいて、定量的なものが採用されていないのが気になる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMによる評価だけで良いのかはとても疑問&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Gemma以外のモデルの性能はどうなのだろう&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>イン・ザ・プール</title>
      <link>http://localhost:1313/post/book/20251122182948-%E3%82%A4%E3%83%B3/</link>
      <pubDate>Sat, 22 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20251122182948-%E3%82%A4%E3%83%B3/</guid>
      <description>&lt;p&gt;イン・ザ・プールを読んだ。&#xA;奥田英朗さんによる作品で、精神科医伊良部シリーズの最初の話。&#xA;この医者が変わった病気を持つ人達を治療するかもしれないし、しないかもしれない話だ。&lt;/p&gt;&#xA;&lt;p&gt;全部で五つの短編が集録されていて、読みやすかった。&#xA;集録されているのは以下の五編。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;イン・ザ・プール&lt;/li&gt;&#xA;&lt;li&gt;勃ちっぱなし&lt;/li&gt;&#xA;&lt;li&gt;コンパニオン&lt;/li&gt;&#xA;&lt;li&gt;フレンズ&lt;/li&gt;&#xA;&lt;li&gt;いてもたっても&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;フレンズが一番のお気に入りの作品。&#xA;携帯依存症の高校生の話で、その高校生は日々頑張って友達関係を維持している。&#xA;この友情関係の維持のしかたが、とてもいたたまれない様子で、自分に刺さった。&#xA;こういう時期ってあるよな〜って感情移入できた。&lt;/p&gt;&#xA;&lt;p&gt;全体的に明確に解決しているとは書かれていないが、ネガティブな終わり方もしていなくて、読後感はとても良かった。&lt;/p&gt;&#xA;&lt;p&gt;映画化されているらしい。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/post/book/%E3%83%96%E3%83%A9%E3%83%83%E3%83%89%E3%82%B3%E3%83%90%E3%83%AB%E3%83%88/</link>
      <pubDate>Wed, 19 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/%E3%83%96%E3%83%A9%E3%83%83%E3%83%89%E3%82%B3%E3%83%90%E3%83%AB%E3%83%88/</guid>
      <description>&lt;h2 id=&#34;ブラッド-コバルト&#34;&gt;ブラッド・コバルト&lt;/h2&gt;&#xA;&lt;p&gt;コンゴで行われているコバルト採掘の現場を取材したノンフィクションだった。&#xA;様々なIT企業がコバルトのサプライチェーンの健全さをアピールしているが、実態はそうなっていない。&#xA;低賃金で長時間、危険な環境で採掘の現場で搾取されている労働者が居る。&#xA;採掘時に入るトンネル内の環境が良くない事に加え、崩落して生き埋めになる可能性もある。&#xA;加えて、ウランなどの危険な鉱物が含まれている可能性がある。&#xA;これだけではなく、鉱石を洗うことで生活に使用する河川が汚れることや、児童労働の問題などがある。&lt;/p&gt;&#xA;&lt;p&gt;この本は、普段使っているスマホやPCがコンゴ人の命の上に存在しているという事実を突きつけてきた。&#xA;今となっては、手放すことができない製品だから、この搾取に加担していると言っても過言ではないと思った。&#xA;本の中でも指摘されているが、サプライチェーンの上流に居る自分にとってとても都合が悪い。&#xA;特に、この問題が解決した時に今のスマホの値段が上がるのかなあとか考えた時の気分は最悪だった。&lt;/p&gt;&#xA;&lt;p&gt;現在のコンゴ政府では、汚職撤廃キャンペーンが行われているらしい。&#xA;これに期待したい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SAEs Are Good for Steering - If You Select the Right Features</title>
      <link>http://localhost:1313/post/paper/20251118124125-saes_are_good_for_steering_if_you_select_the_right_features/</link>
      <pubDate>Tue, 18 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251118124125-saes_are_good_for_steering_if_you_select_the_right_features/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.emnlp-main.519/&#34;&gt;SAEs Are Good for Steering – If You Select the Right Features&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;EMNLP 2025 main&lt;/li&gt;&#xA;&lt;li&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;（1, 2文でまとめる）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SAEを用いた特徴量選択において、入力と出力の特徴量のそれぞれに影響がある特徴量を見つけること&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sparse AutoEncoder(SAE)は介入するための特徴量を選択する時に有効な手法である&lt;/li&gt;&#xA;&lt;li&gt;だが、介入のために有効な特徴を選択することはまだ未知の問題である&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徴量を以下の二種類に分類し、分類するための指標を提案した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Input features：モデルに入力されたパターンを認識する特徴量&lt;/li&gt;&#xA;&lt;li&gt;Output features：モデルが生成するトークンに影響する特徴量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;これらの分析には、Logit Lensが使用されている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Logit Lengsはモデルのパラメータを語彙空間に射影し、その出力分布を見てパラメータを分析する方法のこと&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Input featuresのスコアの計算には、任意の文章集合を用いる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;この文章集合において最も大きくSAEのトークンを発火させたトークンと、Logit Lensにより予測されたトークンの一致率をスコアとしている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Output Featuresのスコアの計算にはLogit Lensにより予測されたトークンのスコアと順位、確率を使用する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;その特徴量に介入を行った時のモデルの出力分布と介入をする前の分布の差をスコアとしている&lt;/li&gt;&#xA;&lt;li&gt;Logit Lensによる予測結果を用いて介入する前の出力分布を計算しているが、よく分からなかった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;上記のスコアをGemmaやLlamaに適用した所、Gemmaにおいては入力に近い層ではInput features、出力に近い層ではOutput Featuresのスコアが大きくなっていた。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;それ以外のモデルにおいては、この傾向は当てはまっていない&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Output featuresが高いパラメータに介入することによる出力文章の変化を計算した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;実験では、スコアに閾値を用意し介入する特徴量を選択している&lt;/li&gt;&#xA;&lt;li&gt;評価には、Generation Success@Kを使用している。&lt;/li&gt;&#xA;&lt;li&gt;Logit Lensにより予測されたTop-kのトークンと文章に含まれるトークンの一致率を計算している。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;閾値を上げると、Generation Success@Kが上昇することが分かった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;スコアの計算結果で、きれいな結果が出ているのがGemmaだけなのが気になる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;介入の結果は同様の傾向を示している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;結局Output featuresが高いものが良い特徴であるのか？&lt;/li&gt;&#xA;&lt;li&gt;介入の方法が良く分からなかった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;方向を決める方法が知りたい&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>http://localhost:1313/post/paper/20251117145542-gorilla_large_language_model_connected_with_massive_apis/</link>
      <pubDate>Mon, 17 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251117145542-gorilla_large_language_model_connected_with_massive_apis/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.proceedings.com/079017-4020.html&#34;&gt;Gorilla: Large Language Model Connected with Massive APIs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;NeurIPS 2024&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMのAPIを呼び出す能力は、LLM自身に与えられたAPIのドキュメントが正確であるか判断させながら学習を進めると良い&lt;/li&gt;&#xA;&lt;li&gt;API呼び出しの評価はASTの部分木マッチングを使用すると良い&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが外部のAPIを上手く活用するための学習方法を提案した&lt;/li&gt;&#xA;&lt;li&gt;また、LLMのAPI活用能力を評価するためにベンチマークデータセットを構築した&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;APIを呼び出すためのコードをLLMが生成することはまだ難しいタスクである&lt;/li&gt;&#xA;&lt;li&gt;APIの使用は頻繁に更新されることが原因の一つとして挙げられている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;評価のために、APIBenchと呼ばれるベンチマークデータセットを構築した&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TorchHubなどにアップロードされているモデルカードから仮想APIの呼び出しコードを作成している&lt;/li&gt;&#xA;&lt;li&gt;このAPIについて指示をGPT-4を使用して生成している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Retriever-Aware Training&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プロンプトに含まれているAPIのドキュメントが不正確である可能性がある&lt;/li&gt;&#xA;&lt;li&gt;最初に、プロンプトに含まれているドキュメントが正確であるかを予測する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習データには、不正確なドキュメントを含めるように拡張している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;正確ではない予測した場合、そのドキュンメントを使用して推論しないように学習を促す&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;評価にはASTの部分木マッチングを使用している&#xA;&lt;ul&gt;&#xA;&lt;li&gt;APIの引数には、必要ではないものが存在している&lt;/li&gt;&#xA;&lt;li&gt;そこで、構文木を作っておき、LLMの生成した呼び出しのコードが部分木であるかどうかを判定して評価している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習したモデル（論文中ではGorilla）がベースラインモデル（GPT-4やLLama）よりzero-shotやFew-shotで良い性能であった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Few-shotに使用するRetrieverを変えても同様の結果になった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ASTによる評価は、人手評価と同様の性能を示している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;実装のイメージがつかない&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMが与えられたドキュメントを判断した後に、プロンプトの文言を追加するという事なのか&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Gorillaはオリジナルのモデルではないよな？&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Llamaベースのモデルになると思うが、シンプルなSFTをした時との比較は無いのだろうか&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>SAE-SSV:Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models</title>
      <link>http://localhost:1313/post/paper/20251115102210-sae_ssv_supervised_steering_in_sparse_representation_spaces_for_reliable_control_of_language_models/</link>
      <pubDate>Sat, 15 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251115102210-sae_ssv_supervised_steering_in_sparse_representation_spaces_for_reliable_control_of_language_models/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2025.emnlp-main.112/&#34;&gt;SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;EMNLP 2025 main&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SAEを用いた特徴量を用いて介入を行うことで、LLMをより良く制御することができる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;自由記述タスクにおけるLLMへのパラメータ介入手法の性能を向上すること&lt;/li&gt;&#xA;&lt;li&gt;特に、介入に使用する適切なベクトルを構築することを目的する&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMの生成文章を制御する方法として、中間表現を制御するステアリングがある&lt;/li&gt;&#xA;&lt;li&gt;既存のステアリング手法の評価は、QAや選択問題などの制約がある&lt;/li&gt;&#xA;&lt;li&gt;加えて、ヒューリスティックな方法であるため文脈などを取りこぼすことがある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sparse Auto Encoder(SAE)を使用して、介入する方向を決めること&#xA;&lt;ul&gt;&#xA;&lt;li&gt;エンコーダの出力が、入力次元数よりも大きいAuto Encoderのこと&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;SAEが抽出したベクトル表現を使用して、Probingを行いそのタスクにおいて有効な特徴量を見つけている&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徴量を見つけるために、F-Statisticを使用して次元削減をしているっぽい&lt;/li&gt;&#xA;&lt;li&gt;これ以外にも、学習した線形モデル（Probe）の次元削減をするための工夫がある&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;複数のProbeを学習し、その平均ベクトルを介入ベクトルとする&lt;/li&gt;&#xA;&lt;li&gt;この介入ベクトルを最適化するために、追加の学習をすることで微調整する&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ポジティブとネガティブに分類されたデータからSAEが抽出した特徴量に介入する&lt;/li&gt;&#xA;&lt;li&gt;この介入後の特徴量が、ポジティブなデータとネガティブなデータの特徴量のセントロイドに近くなるように学習する&lt;/li&gt;&#xA;&lt;li&gt;加えて、言語モデル自体の損失関数や介入ベクトルに対するL1損失を制約として使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;性能的には、既存の介入手法よりも良いスコアになっている&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;SAEにより抽出された特徴量が良くクラスを分類できる特徴量になっていることが分かった&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SAEによる特徴量の抽出を用いた介入の有効性を示している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Ablation Studyにより損失関数の必要性が示されている&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Probeの学習を行わないと、出力文章の整合性や論理性が無くなる&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;言語モデルの損失を無くすと、ベースになる言語モデルの応答を保持することが難しくなる&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;介入の方向については提案手法で良い方向を見つけることができたが、大きさについては未知である&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;手法が複雑だと思った&lt;/li&gt;&#xA;&lt;li&gt;SAEの学習やProbingの調整に必要な計算コストがどれくらいなのが気になる&lt;/li&gt;&#xA;&lt;li&gt;評価にLLMを使用するのが適切であるかどうか分からない&#xA;&lt;ul&gt;&#xA;&lt;li&gt;生成された文章が対象の文章を適切に反映できているのかを評価させている&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ベースモデルの評価が無いのが気になる&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ablation Studyに一応あった&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets</title>
      <link>http://localhost:1313/post/paper/20251110102131-apigen_automated_pipeline_for_generating_verifiable_and_diverse_function_calling_datasets/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/paper/20251110102131-apigen_automated_pipeline_for_generating_verifiable_and_diverse_function_calling_datasets/</guid>
      <description>&lt;h2 id=&#34;論文情報&#34;&gt;📄論文情報&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.proceedings.com/content/079/079017-1725open.pdf&#34;&gt;APIGen: Automated PIpeline for Generating Verifiable and Diverse Function-Calling Datasets&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;NeurIPS2024&lt;/li&gt;&#xA;&lt;li&gt;Salesforceの著者らによるもの&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;この論文のキーメッセージ&#34;&gt;🔑この論文のキーメッセージ&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLMのFunction Callingの性能向上のためには、多くのAPIに関する情報があると良い&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;どういう問題に取り組んだのか&#34;&gt;🎓どういう問題に取り組んだのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Function Callingとは、自然言語の指示にの応答を生成するために必要なAPIを叩き、必要な情報を得るタスクのことを指す&lt;/li&gt;&#xA;&lt;li&gt;この論文では、このタスクの学習に必要なデータを自動生成するためのパイプラインを提案している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;その問題に取り組むことがなぜ重要なのか&#34;&gt;🧑‍🎓その問題に取り組むことがなぜ重要なのか&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;既存のfunction callingデータセットは実用のためには不十分である&#xA;&lt;ul&gt;&#xA;&lt;li&gt;例えば、学習データ内で使用されているAPIが一部のカテゴリに偏っている場合、そのデータで学習されたLLMエージェントは他のAPIからのデータの取得ができなくなるという課題がある。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;そのため、多様なAPIを扱うデータセットが必要になる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題解決に向けたキーアイデアは何か&#34;&gt;💡問題解決に向けたキーアイデアは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提案手法は、データの生成と多段階によるフィルタリングから構成されている&lt;/li&gt;&#xA;&lt;li&gt;データの生成&#xA;&lt;ol&gt;&#xA;&lt;li&gt;既存のAPIを用いたQAペアをJSON形式に変する。&lt;/li&gt;&#xA;&lt;li&gt;プロンプトはデータ生成の目的になるテンプレートを選択し、QAペアを生成させる&lt;/li&gt;&#xA;&lt;li&gt;生成されたペアをJSON形式に変換する&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;生成されたデータをフィルタするために以下の3つの方法を用いる&#xA;&lt;ol&gt;&#xA;&lt;li&gt;フォーマットの検証：生成されたJSONのフォーマットが正しいか、APIの呼び出し時に適切な引数を指定しているか検証する&lt;/li&gt;&#xA;&lt;li&gt;実行可能性の検証：データに含まれたAPIが実行可能であるか検証する、実行可能ではない場合、フィルターする&lt;/li&gt;&#xA;&lt;li&gt;文法の検証：複数のLLMを用いて、目的を達成するための関数を呼び出すことができるかなどを総合的に評価する&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;データの多様性を確保するために、テンプレートを複数用意することや、基データからどのようなデータをサンプリングするかを工夫している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;新たに分かったことは何か&#34;&gt;👀新たに分かったことは何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ToolBenchを基データとして生成を行った&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基データとして活用するために、いくつかのフィルターを適用したの3500件を使用している&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;生成パイプラインを様々なLLMを用いて検証した所、小規模なモデルは無効なAPIを呼び出る例が多い&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学習したモデルの評価はBerkley Function-Callingデータセットを使用している&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;FCのために学習されたLLMはGPT-4oなどよりも良い性能を示している&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学習に使用しているLLMは1Bと7Bのモデルなので、より小規模なパラメータになっているかも？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;各フィルタリングステップにおいて、フィルター後のデータを用いてモデルを学習し、評価した&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;上の説明において、フォーマットの検証のみを適用したデータ、1と2を適用したデータ、全てを適用したデータに分けている&lt;/li&gt;&#xA;&lt;li&gt;評価結果としては、全てを適用したデータにより学習されたLLMの性能が最も良かった&lt;/li&gt;&#xA;&lt;li&gt;このことから、提案したフィルター方法の有効性が分かる&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;疑問点は何か&#34;&gt;❓疑問点は何か&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPTとかのモデルの比較って平等な比較になっているのか疑問だった&lt;/li&gt;&#xA;&lt;li&gt;生成されたデータの多様性の評価は行われていないのが気になった&#xA;&lt;ul&gt;&#xA;&lt;li&gt;プロンプトのテンプレやデータの持ってき方の工夫で十分なのかな&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>嫉妬論</title>
      <link>http://localhost:1313/post/book/20251109125003-%E5%AB%89%E5%A6%AC%E8%AB%96/</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/book/20251109125003-%E5%AB%89%E5%A6%AC%E8%AB%96/</guid>
      <description>&lt;p&gt;嫉妬という感情を巡る議論についての本だった。&#xA;とりわけ、嫉妬が類似している者同士の間に生じるものという指摘はとても分かるなあと思った。&lt;/p&gt;&#xA;&lt;p&gt;妬まれないための戦略に、ロゴがデザインに組み込まれているハイブランドが嫌いである理由が言語化されている気がした。&#xA;戦略として、「隠蔽」「否認」「賄賂」「共有」という4つの戦略が挙げられていた。&#xA;この中の隠蔽については、妬みの対象となるものを隠す行動を指す。&#xA;ロゴが入っていることにより、隠蔽という戦略が無効になり、妬みが想起されてしまう。&#xA;これまでは上手く言語かできていなかったけど、上手く言語化されていて、腑に落ちた。&lt;/p&gt;&#xA;&lt;p&gt;これまでの思想家が嫉妬についてどのように論じてきたかもまとめられていた。&#xA;会話の0.2秒を言語学するという本で、著者が哲学について、当たり前のことに理屈っぽく取り組んでいる様を面白がると良いとあった。&#xA;この本自体ぶ厚くないから、この面白さをを味わうのにとても良かった。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emacsでlua-language-serverを動かす</title>
      <link>http://localhost:1313/post/tech/20251008094413-emacs%E3%81%A7lua_language_server%E3%82%92%E5%8B%95%E3%81%8B%E3%81%99/</link>
      <pubDate>Wed, 08 Oct 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/tech/20251008094413-emacs%E3%81%A7lua_language_server%E3%82%92%E5%8B%95%E3%81%8B%E3%81%99/</guid>
      <description>&lt;p&gt;Emacsのlsp-modeでlua-language-serverを動かそうとしたら、ハマったのでメモ。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://zenn.dev/mozumasu/articles/mozumasu-wezterm-customization&#34;&gt;モテるターミナルにカスタマイズしよう（WezTerm）&lt;/a&gt;を見て、weztermを設定しようとした。&lt;/p&gt;&#xA;&lt;p&gt;設定ファイルである &lt;code&gt;wezterm.lua&lt;/code&gt; をEmacsで編集するためにluaの環境を整えようとしたら、Lua-language-serverを &lt;code&gt;lsp-mode&lt;/code&gt; が認識しなかった。&lt;/p&gt;&#xA;&lt;p&gt;加えて、自動でインストールしようとしたら、emacsがフリーズしてしまった。&lt;/p&gt;&#xA;&lt;p&gt;動作させるために必要だった設定は以下の通り。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-emacs-lisp&#34; data-lang=&#34;emacs-lisp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;setq&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-bin&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;format&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;%s/.nix-profile/bin/lua-language-server&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;getenv&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;HOME&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-main-location&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;format&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;%s/.lua-language-server/main.lua&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;getenv&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;HOME&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;; reference : https://github.com/emacs-lsp/lsp-mode/issues/4688#issuecomment-3138937688&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;defun&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;my/lsp-clients-lua-language-server-test&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s&#34;&gt;&amp;#34;(Improved) Test Lua language server binaries and files.&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;f-exists?&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-main-location&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;f-exists?&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-bin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;f-exists?&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;car&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;split-string&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;advice-add&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;#&amp;#39;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;lsp-clients-lua-language-server-test&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;:override&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;#&amp;#39;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;my/lsp-clients-lua-language-server-test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;lsp-mode自体にもIssueが上っていたためそれを参考にして設定したら動作した。&lt;/p&gt;&#xA;&lt;p&gt;私はnixを使用してlua-language-serverをインストールしている。&#xA;インストールする時に、lua-language-serverの &lt;code&gt;main.lua&lt;/code&gt; を適当な場所に配置する。&lt;/p&gt;&#xA;&lt;p&gt;この &lt;code&gt;main.lua&lt;/code&gt; の場所を &lt;code&gt;lsp-clients-lua-language-server-main-location&lt;/code&gt; に設定し、 &lt;code&gt;lsp-clients-lua-language-server-bin&lt;/code&gt; にlua-language-serverをインストールしたPathを設定する。&lt;/p&gt;&#xA;&lt;p&gt;最後に、&lt;a href=&#34;https://github.com/emacs-lsp/lsp-mode/issues/4688#issuecomment-3138937688&#34;&gt;このIssueコメント&lt;/a&gt;にある関数をコピペしたら動いた。&lt;/p&gt;&#xA;&lt;p&gt;参考 : &lt;a href=&#34;https://github.com/emacs-lsp/lsp-mode/issues/4688&#34;&gt;Externally provided lua-language-server is not recognized #4688&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>HugoのGithub Styleに自作のメニューを付ける</title>
      <link>http://localhost:1313/post/tech/20251007164516-hugo%E3%81%AEgithub_style%E3%81%AB%E7%8B%AC%E8%87%AA%E3%81%AE%E3%83%A1%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%92%E4%BB%98%E3%81%91%E3%82%8B/</link>
      <pubDate>Tue, 07 Oct 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/tech/20251007164516-hugo%E3%81%AEgithub_style%E3%81%AB%E7%8B%AC%E8%87%AA%E3%81%AE%E3%83%A1%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%92%E4%BB%98%E3%81%91%E3%82%8B/</guid>
      <description>&lt;p&gt;このブログは&lt;a href=&#34;https://gohugo.io&#34;&gt;Hugo&lt;/a&gt;の&lt;a href=&#34;https://themes.gohugo.io/themes/github-style/&#34;&gt;Github Style&lt;/a&gt;を少し設定している。&lt;/p&gt;&#xA;&lt;p&gt;デフォルトだと、自己紹介などがブログに埋もれてしまうためメニューバーに追加した。&lt;/p&gt;&#xA;&lt;p&gt;現状、一つ加える度にhtmlを触らないといけない実装になっているのが気になるが、動いているからヨシ!&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;config.toml&lt;/code&gt; に以下の要素を追加して、設定ファイルに追記すれば要素が追加されるようにした。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Self&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nx&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;introduction/introduction&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;そして、作成したHugoプロジェクト以下に &lt;code&gt;layouts/partial/menu.html&lt;/code&gt; を作る。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;menus.html&lt;/code&gt; の追加のメニューとして以下の変更を加えた。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{ range .Site.Params.projects }}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;UnderlineNav-item&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;          {{ if .IsSection }}  selected  {{ end }}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;          {{ if eq .Type &amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;tags&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;}}&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;selected&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;}}&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;na&#34;&gt;href&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;{{ absURL .url }}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{ .name}}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{ end }}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既存の実装では、リンクを貼る実装が &lt;code&gt;{{urls.JoinPath .Site.BaseURL url}}&lt;/code&gt; になってる。&lt;/p&gt;&#xA;&lt;p&gt;だが、上手く動作してくれなかったので &lt;code&gt;{{absURL .url}}&lt;/code&gt; という実装にしている。&lt;/p&gt;</description>
    </item>
    <item>
      <title>チェーンソーマン レゼ編</title>
      <link>http://localhost:1313/post/movie/20251007082221-%E3%83%81%E3%82%A7%E3%83%BC%E3%83%B3%E3%82%BD%E3%83%BC%E3%83%9E%E3%83%B3_%E3%83%AC%E3%82%BC%E7%B7%A8/</link>
      <pubDate>Tue, 07 Oct 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/movie/20251007082221-%E3%83%81%E3%82%A7%E3%83%BC%E3%83%B3%E3%82%BD%E3%83%BC%E3%83%9E%E3%83%B3_%E3%83%AC%E3%82%BC%E7%B7%A8/</guid>
      <description>&lt;p&gt;チェーンソーマン レゼ編を見た&lt;/p&gt;&#xA;&lt;p&gt;漫画では分からなかったシーンが補完されていて、面白かった。&lt;/p&gt;&#xA;&lt;p&gt;この映画では、爆弾の悪魔であるレゼと主人公であるデンジが出会い、戦うまでが描かれている。&lt;/p&gt;&#xA;&lt;p&gt;デンジがレゼと祭りに行く辺りから戦闘に移行するまでの音楽の変化が印象的で、戦闘シーンの派手さが強烈だった。&lt;/p&gt;&#xA;&lt;p&gt;デンジとレゼが祭りに言っている時は幸せそうな音楽なのに、戦闘が近づくにつれて不協和音が混ざっていく様子が、く、くる。。。という雰囲気がした。&lt;/p&gt;&#xA;&lt;p&gt;祭り以外にも、戦闘中の曲にマキシマム・ザ・ホルモンの刃渡り二億センチがとてもマッチしていたのを覚えている。&lt;/p&gt;&#xA;&lt;p&gt;戦闘シーンの派手さは強烈だった。&lt;/p&gt;&#xA;&lt;p&gt;爆弾の悪魔だけあって、爆発のエフェクトや音、鮫の魔人が頑張って移動する様子が映像化されていて、より漫画を読むのが楽しめるようになったのが良かった。&lt;/p&gt;&#xA;&lt;p&gt;鮫の魔人の移動の仕方が気持ち悪かったなあ。&lt;/p&gt;&#xA;&lt;p&gt;この先の話もきっと映像化されるだあろうし、楽しみだ。&lt;/p&gt;</description>
    </item>
    <item>
      <title>よく使用する画像サイト</title>
      <link>http://localhost:1313/post/memo/20250930200606-%E3%82%88%E3%81%8F%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E7%94%BB%E5%83%8F%E3%82%B5%E3%82%A4%E3%83%88/</link>
      <pubDate>Tue, 30 Sep 2025 00:00:00 +0900</pubDate>
      <guid>http://localhost:1313/post/memo/20250930200606-%E3%82%88%E3%81%8F%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E7%94%BB%E5%83%8F%E3%82%B5%E3%82%A4%E3%83%88/</guid>
      <description>&lt;p&gt;スライド作りや論文のための図のために使用するフリー素材のサイトをまとめておく。&lt;/p&gt;&#xA;&lt;h2 id=&#34;論文で使うサイト&#34;&gt;論文で使うサイト&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://soco-st.com&#34;&gt;ソコスト&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;最近よく使っている。&lt;/p&gt;&#xA;&lt;p&gt;EPSで画像がダウンロードできる、かつ、画像の一部を好きな色にできるのがお気に入りポイント。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!--listend--&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://icooon-mono.com/&#34;&gt;Icon-mono&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;白黒のシンプルなイラストがある。最近使ってない。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;スライドで使うサイト&#34;&gt;スライドで使うサイト&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.irasutoya.com&#34;&gt;いらすとや&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;圧倒的便利さ。画像を眺めるだけで楽しい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction</title>
      <link>http://localhost:1313/introduction/introduction/</link>
      <pubDate>Sun, 14 Sep 2025 20:23:15 +0900</pubDate>
      <guid>http://localhost:1313/introduction/introduction/</guid>
      <description>&lt;h2 id=&#34;学歴&#34;&gt;学歴&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;博士 (学術) 2025/04~現在&lt;/p&gt;&#xA;&lt;p&gt;東京大学総合文化研究科広域システム科学系&lt;/p&gt;&#xA;&lt;p&gt;指導教員：&lt;a href=&#34;https://yukinobaba.jp/&#34;&gt;馬場 雪乃准教授&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;修士 (学術) 2023/04~2025/03&lt;/p&gt;&#xA;&lt;p&gt;東京大学総合文化研究科広域システム科学系&lt;/p&gt;&#xA;&lt;p&gt;指導教員：&lt;a href=&#34;https://yukinobaba.jp/&#34;&gt;馬場 雪乃准教授&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学士 (情報工学) 2021/04~2023/03&lt;/p&gt;&#xA;&lt;p&gt;筑波大学情報学群情報科学類&lt;/p&gt;&#xA;&lt;p&gt;指導教員：&lt;a href=&#34;https://yukinobaba.jp/&#34;&gt;馬場 雪乃准教授&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;準学士 2014/04~2021/03&lt;/p&gt;&#xA;&lt;p&gt;豊田工業高等専門学校情報工学科&lt;/p&gt;&#xA;&lt;p&gt;指導教員：&lt;a href=&#34;https://mnacsm.github.io/&#34;&gt;村田 匡輝准教授&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;論文-査読付き&#34;&gt;論文 (査読付き)&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;WIP&amp;hellip;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;論文-査読無し&#34;&gt;論文 (査読無し)&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://yans.anlp.jp/entry/yans2024program&#34;&gt;タスク特徴を考慮したマッチング制約下におけるアノテーション割り当て&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;u&gt;守山 慧&lt;/u&gt;,中山 功太,馬場 雪乃&lt;/p&gt;&#xA;&lt;p&gt;NLP若手の会 (YANS) 第19回シンポジウム&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P3-6.pdf&#34;&gt;マッチング数制約下でのアノテーション検証割り当ての自動化&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;u&gt;守山 慧&lt;/u&gt;,中山 功太,馬場 雪乃&lt;/p&gt;&#xA;&lt;p&gt;言語処理学会第30回年次大会 発表論文集(NLP2024)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A5-4.pdf&#34;&gt;文献理解のための人間の応答を利用したプロンプト最適化&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;今川 涼平,&lt;u&gt;守山 慧&lt;/u&gt;,楊 明哲,馬場 雪乃&lt;/p&gt;&#xA;&lt;p&gt;言語処理学会第30回年次大会 発表論文集(NLP2024)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://yans.anlp.jp/entry/yans2023program#1750-1850-%E3%83%9D%E3%82%B9%E3%82%BF%E3%83%BC%E3%82%BB%E3%83%83%E3%82%B7%E3%83%A7%E3%83%B3-3&#34;&gt;Wisdom of Prompts：プロンプトの重みづけによるLLMの精度向上&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;u&gt;守山 慧&lt;/u&gt;,中山 功太,馬場 雪乃&lt;/p&gt;&#xA;&lt;p&gt;NLP若手の会 (YANS) 第18回シンポジウム&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/P9-7.pdf&#34;&gt;専門家と非専門家によるアノテーション検証割り当ての自動化&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;u&gt;守山 慧&lt;/u&gt;,中山 功太,馬場 雪乃&lt;/p&gt;&#xA;&lt;p&gt;言語処理学会第29回年次大会 発表論文集(NLP2023)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;受賞&#34;&gt;受賞&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;令和7年度広域科学専攻奨励賞&lt;/li&gt;&#xA;&lt;li&gt;令和5年度筑波大学心青会賞&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;インターンアルバイト&#34;&gt;インターン・アルバイト&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://llmc.nii.ac.jp/&#34;&gt;大規模言語モデル研究開発センター(LLMC)&lt;/a&gt; (2024/09 - now)&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/readme/</guid>
      <description>&lt;p&gt;所属 : 東京大学総合文化研究科広域科学専攻広域システム科学系&#xA;学年 : D1&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
